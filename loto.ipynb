{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e1692ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68eb7816",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_files = r'./tirages/*.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18283aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4858, 7)\n",
      "(310, 7)\n",
      "(107, 7)\n",
      "(455, 7)\n",
      "(1317, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7047, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = glob.glob(path_files)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#filename = all_files[0]\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, sep=';', parse_dates=['date_de_tirage'], dayfirst=True)\n",
    "    \n",
    "    df = df[[\"date_de_tirage\", \"boule_1\", \"boule_2\", \"boule_3\", \"boule_4\", \"boule_5\", \"numero_chance\"]]\n",
    "    \n",
    "    df.rename(columns={\n",
    "        'date_de_tirage': 'date_tirage',\n",
    "        'boule_1': 'num0',\n",
    "        'boule_2':'num1', \n",
    "        \"boule_3\": \"num2\", \n",
    "        \"boule_4\": \"num3\", \n",
    "        \"boule_5\": \"num4\", \n",
    "        \"numero_chance\": \"chance\"},inplace=True)\n",
    "    print(df.shape)\n",
    "    df_list.append(df)\n",
    "    #break;\n",
    "\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "# placer le dernier tirage en dernière position\n",
    "df.sort_values('date_tirage', ascending = True, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c85e8b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_tirage</th>\n",
       "      <th>num0</th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "      <th>num3</th>\n",
       "      <th>num4</th>\n",
       "      <th>chance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>1976-05-19</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>1976-06-03</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>1976-06-10</td>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4854</th>\n",
       "      <td>1976-06-16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4853</th>\n",
       "      <td>1976-06-23</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     date_tirage  num0  num1  num2  num3  num4  chance\n",
       "4857  1976-05-19    31    15    33    27    36      34\n",
       "4856  1976-06-03    10    26    42     1     4      31\n",
       "4855  1976-06-10    44    16    47    10    15      27\n",
       "4854  1976-06-16     2     3    35    13     1      49\n",
       "4853  1976-06-23    30    22    11     9    23      49"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f797c711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_tirage</th>\n",
       "      <th>num0</th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "      <th>num3</th>\n",
       "      <th>num4</th>\n",
       "      <th>chance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-09-21</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>29</td>\n",
       "      <td>49</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_tirage  num0  num1  num2  num3  num4  chance\n",
       "4  2022-09-19     5     7    44    15    33       1\n",
       "3  2022-09-21     3    12    22     9    37      10\n",
       "2  2022-09-24    25     6    32     7     4      10\n",
       "1  2022-09-26    29    49    35    18    39       1\n",
       "0  2022-09-28    12    39    26    14    29      10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8bfa8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num0</th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "      <th>num3</th>\n",
       "      <th>num4</th>\n",
       "      <th>chance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4854</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4853</th>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num0  num1  num2  num3  num4  chance\n",
       "4857    31    15    33    27    36      34\n",
       "4856    10    26    42     1     4      31\n",
       "4855    44    16    47    10    15      27\n",
       "4854     2     3    35    13     1      49\n",
       "4853    30    22    11     9    23      49"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"num0\", \"num1\", \"num2\", \"num3\", \"num4\", \"chance\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8159b45b",
   "metadata": {},
   "source": [
    "https://github.com/berba1995/Deep_Learning_et_le_Hasard/blob/main/DEEP_LEARNING_ET_LE_HASARD.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3f3c48b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fonction de vérification de nombres en dessous d'une certaine valeur pour les 5 premiers numéros, sauf celui de chance\n",
    "def is_under(data, number):\n",
    "    return ((data['num0'] <= number).astype(int) + \n",
    "            (data['num1'] <= number).astype(int) +\n",
    "            (data['num2'] <= number).astype(int) +\n",
    "            (data['num3'] <= number).astype(int) +\n",
    "            (data['num4'] <= number).astype(int))\n",
    "\n",
    "#fonction de vérification de nombres pairs pour les 5 premiers numéros sauf celui de chance\n",
    "def is_pair(data):\n",
    "    return ((data['num0'].isin(pairs)).astype(int) + \n",
    "            (data['num1'].isin(pairs)).astype(int) +\n",
    "            (data['num2'].isin(pairs)).astype(int) +\n",
    "            (data['num3'].isin(pairs)).astype(int) +\n",
    "            (data['num4'].isin(pairs)).astype(int))\n",
    "\n",
    "#fonction de vérification de nombres impairs pour les 5 premiers numéros sauf celui de chance\n",
    "def is_impair(data):\n",
    "    return ((data['num0'].isin(impairs)).astype(int) + \n",
    "            (data['num1'].isin(impairs)).astype(int) +\n",
    "            (data['num2'].isin(impairs)).astype(int) +\n",
    "            (data['num3'].isin(impairs)).astype(int) +\n",
    "            (data['num4'].isin(impairs)).astype(int))\n",
    "\n",
    "#fonction de vérification de nombres pairs pour le numéro de chance\n",
    "def is_pair_etoile(data):\n",
    "    return (data['chance'].isin(pairs)).astype(int)\n",
    "\n",
    "#fonction de vérification de nombres impairs pour le numéro de chance\n",
    "def is_impair_etoile(data):\n",
    "    return (data['chance'].isin(impairs)).astype(int)\n",
    "\n",
    "#liste de nombres pairs et impairs\n",
    "pairs = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50]\n",
    "impairs = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]\n",
    "\n",
    "#Fonction de calcul de la somme de la différence au carré des 5 premiers numéros, sauf celui de chance\n",
    "def sum_diff(data):\n",
    "    return ((data['num1'] - data['num0'])**2 + \n",
    "            (data['num2'] - data['num1'])**2 +\n",
    "            (data['num3'] - data['num2'])**2 +\n",
    "            (data['num4'] - data['num3'])**2)\n",
    "\n",
    "\n",
    "# Calcul de la fréquence de tirage de chaque numéro\n",
    "freqs = []\n",
    "for val in range(50):\n",
    "    count = ( (df['num0'] == val+1).sum() +\n",
    "              (df['num1'] == val+1).sum() +\n",
    "              (df['num2'] == val+1).sum() +\n",
    "              (df['num3'] == val+1).sum() +\n",
    "              (df['num4'] == val+1).sum() )\n",
    "    freqs.append(count)\n",
    "ax = plt.gca() ;  ax.invert_yaxis()\n",
    "plt.gcf().set_size_inches(5, 4)\n",
    "heatmap = plt.pcolor(np.reshape(np.array(freqs), (5, 10)), cmap=plt.cm.Blues)\n",
    "\n",
    "def freq_val(data, column):\n",
    "    tab = data[column].values.tolist()\n",
    "    freqs = []\n",
    "    pos = 1\n",
    "    for e in tab:\n",
    "        freqs.append(tab[0:pos].count(e))\n",
    "        pos = pos + 1\n",
    "    return freqs\n",
    "\n",
    "\n",
    "\n",
    "#df['sum'] = ((df.num0 + df.num1 + df.num2 + df.num3 + df.num4 + df.chance ) >185).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8e70c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num0</th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "      <th>num3</th>\n",
       "      <th>num4</th>\n",
       "      <th>chance</th>\n",
       "      <th>freq_num0</th>\n",
       "      <th>freq_num1</th>\n",
       "      <th>freq_num2</th>\n",
       "      <th>freq_num3</th>\n",
       "      <th>freq_num4</th>\n",
       "      <th>freq_chance</th>\n",
       "      <th>sum_diff</th>\n",
       "      <th>pair_chance</th>\n",
       "      <th>impair_chance</th>\n",
       "      <th>pair</th>\n",
       "      <th>impair</th>\n",
       "      <th>is_under_24</th>\n",
       "      <th>is_under_40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>697</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2202</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3139</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4854</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1653</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4853</th>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>385</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4852</th>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1113</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      num0  num1  num2  num3  num4  chance  freq_num0  freq_num1  freq_num2  \\\n",
       "4857    31    15    33    27    36      34          1          1          1   \n",
       "4856    10    26    42     1     4      31          1          1          1   \n",
       "4855    44    16    47    10    15      27          1          1          1   \n",
       "4854     2     3    35    13     1      49          1          1          1   \n",
       "4853    30    22    11     9    23      49          1          1          1   \n",
       "4852    10    17    25    35     5       1          2          1          1   \n",
       "\n",
       "      freq_num3  freq_num4  freq_chance  sum_diff  pair_chance  impair_chance  \\\n",
       "4857          1          1            1       697            1              0   \n",
       "4856          1          1            1      2202            0              1   \n",
       "4855          1          1            1      3139            0              1   \n",
       "4854          1          1            1      1653            0              1   \n",
       "4853          1          1            2       385            0              1   \n",
       "4852          1          1            1      1113            0              1   \n",
       "\n",
       "      pair  impair  is_under_24  is_under_40  \n",
       "4857     1       4            1            5  \n",
       "4856     4       1            3            4  \n",
       "4855     3       2            3            3  \n",
       "4854     1       4            4            5  \n",
       "4853     2       3            4            5  \n",
       "4852     1       4            3            5  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ajout de la difference entre les numéros(A explorer ASAp)\n",
    "#for i in range(4):\n",
    "    #print(i,i+1)\n",
    "    #df['diff_{}'.format(i)]=df['num{}'.format(i+1)]-df['num{}'.format(i)]\n",
    "#application des fonctions sur le dataframe\n",
    "df['freq_num0'] = freq_val(df, 'num0')\n",
    "df['freq_num1'] = freq_val(df, 'num1')\n",
    "df['freq_num2'] = freq_val(df, 'num2')\n",
    "df['freq_num3'] = freq_val(df, 'num3')\n",
    "df['freq_num4'] = freq_val(df, 'num4')\n",
    "df['freq_chance'] = freq_val(df, 'chance')#calcul des frequences \n",
    "df['sum_diff'] = sum_diff(df)#somme de la différence au carré entre chaque couple de numéros successifs dans le tirage\n",
    "df['pair_chance'] = is_pair_etoile(df)\n",
    "df['impair_chance'] = is_impair_etoile(df)\n",
    "df['pair'] = is_pair(df)\n",
    "df['impair'] = is_impair(df)#verification de nombre pair et impair\n",
    "df['is_under_24'] = is_under(df, 24)  # Les numeros en dessous de 24 \n",
    "df['is_under_40'] = is_under(df, 40)# Les numeros en dessous de 40 \n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637e0852",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c4a7992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params du modèle\n",
    "nb_label_feature=6\n",
    "\n",
    "window_length =12 #12 \n",
    "number_of_features = df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52c967f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de formatage des données en entrée du modèle\n",
    "def loto_dataset(df, window_length,nb_label_feature, scaled = True):\n",
    "    number_of_rows = df.shape[0]   #taille du dataset number_of_features\n",
    "    number_of_features = df.shape[1]\n",
    "    \n",
    "    scaler = None\n",
    "    \n",
    "    if scaled:\n",
    "        scaler = StandardScaler().fit(df.values)\n",
    "        transformed_dataset = scaler.transform(df.values)\n",
    "        df = pd.DataFrame(data=transformed_dataset, index=df.index)\n",
    "\n",
    "    train = np.empty([number_of_rows-window_length, window_length, number_of_features], dtype=float)\n",
    "    \n",
    "    label = np.empty([number_of_rows-window_length, nb_label_feature], dtype=float)\n",
    "    for i in range(0, number_of_rows-window_length):\n",
    "        train[i] = df.iloc[i:i+window_length, 0: number_of_features]\n",
    "        label[i] = df.iloc[i+window_length: i+window_length+1, 0:nb_label_feature]\n",
    "        \n",
    "\n",
    "        \n",
    "    return train, label, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eafcd02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, scaler = loto_dataset(df, window_length,nb_label_feature, scaled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d61133bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c85cf5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4713, 12, 19) (2322, 12, 19) (4713, 6) (2322, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf94cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9e51976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "from keras.layers import LSTM, Dense, Bidirectional, TimeDistributed, RepeatVector, Flatten\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7322a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "units = 100\n",
    "batch_size = 30\n",
    "epochs = 1500\n",
    "\n",
    "window_length = df.shape[0] #12\n",
    "nb_label_feature=6\n",
    "number_of_features = df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0469dfeb",
   "metadata": {},
   "source": [
    "### Réseau Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ea245c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = Sequential()\n",
    "\n",
    "dense.add(LSTM(units, input_shape=(window_length, number_of_features), return_sequences=True))\n",
    "dense.add(LSTM(units, dropout=0.1, return_sequences=False))\n",
    "#ajout de la couche de sortie\n",
    "dense.add(Dense(nb_label_feature))\n",
    "\n",
    "es = EarlyStopping(monitor='accuracy', mode='max', verbose=1, patience=100) # acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9eb69f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dense.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=['acc'])\n",
    "dense.compile(loss = 'mae', optimizer = 'adam', metrics = ['accuracy'])   # categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d432f63f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "126/126 [==============================] - 16s 53ms/step - loss: 0.8311 - accuracy: 0.2398 - val_loss: 0.8413 - val_accuracy: 0.2131\n",
      "Epoch 2/1500\n",
      "126/126 [==============================] - 4s 35ms/step - loss: 0.8251 - accuracy: 0.2435 - val_loss: 0.8401 - val_accuracy: 0.2131\n",
      "Epoch 3/1500\n",
      "126/126 [==============================] - 4s 33ms/step - loss: 0.8226 - accuracy: 0.2379 - val_loss: 0.8412 - val_accuracy: 0.2153\n",
      "Epoch 4/1500\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.8205 - accuracy: 0.2549 - val_loss: 0.8466 - val_accuracy: 0.2163\n",
      "Epoch 5/1500\n",
      "126/126 [==============================] - 4s 33ms/step - loss: 0.8189 - accuracy: 0.2488 - val_loss: 0.8454 - val_accuracy: 0.2131\n",
      "Epoch 6/1500\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.8158 - accuracy: 0.2464 - val_loss: 0.8469 - val_accuracy: 0.2121\n",
      "Epoch 7/1500\n",
      "126/126 [==============================] - 5s 39ms/step - loss: 0.8122 - accuracy: 0.2629 - val_loss: 0.8465 - val_accuracy: 0.2100\n",
      "Epoch 8/1500\n",
      "126/126 [==============================] - 5s 40ms/step - loss: 0.8074 - accuracy: 0.2528 - val_loss: 0.8485 - val_accuracy: 0.2163\n",
      "Epoch 9/1500\n",
      "126/126 [==============================] - 4s 35ms/step - loss: 0.8008 - accuracy: 0.2621 - val_loss: 0.8562 - val_accuracy: 0.2068\n",
      "Epoch 10/1500\n",
      "126/126 [==============================] - 4s 35ms/step - loss: 0.7927 - accuracy: 0.2663 - val_loss: 0.8601 - val_accuracy: 0.1771\n",
      "Epoch 11/1500\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.7831 - accuracy: 0.2782 - val_loss: 0.8665 - val_accuracy: 0.2057\n",
      "Epoch 12/1500\n",
      "126/126 [==============================] - 4s 32ms/step - loss: 0.7727 - accuracy: 0.2851 - val_loss: 0.8689 - val_accuracy: 0.1835\n",
      "Epoch 13/1500\n",
      "126/126 [==============================] - 4s 36ms/step - loss: 0.7571 - accuracy: 0.2923 - val_loss: 0.8729 - val_accuracy: 0.1962\n",
      "Epoch 14/1500\n",
      "126/126 [==============================] - 5s 38ms/step - loss: 0.7431 - accuracy: 0.2934 - val_loss: 0.8803 - val_accuracy: 0.1665\n",
      "Epoch 15/1500\n",
      "126/126 [==============================] - 4s 35ms/step - loss: 0.7259 - accuracy: 0.3268 - val_loss: 0.8808 - val_accuracy: 0.1803\n",
      "Epoch 16/1500\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.7081 - accuracy: 0.3411 - val_loss: 0.8920 - val_accuracy: 0.1729\n",
      "Epoch 17/1500\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.6888 - accuracy: 0.3483 - val_loss: 0.8958 - val_accuracy: 0.1951\n",
      "Epoch 18/1500\n",
      "126/126 [==============================] - 9s 69ms/step - loss: 0.6698 - accuracy: 0.3610 - val_loss: 0.8973 - val_accuracy: 0.1824\n",
      "Epoch 19/1500\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.6491 - accuracy: 0.3716 - val_loss: 0.9073 - val_accuracy: 0.1601\n",
      "Epoch 20/1500\n",
      "126/126 [==============================] - 9s 69ms/step - loss: 0.6300 - accuracy: 0.4048 - val_loss: 0.9058 - val_accuracy: 0.1909\n",
      "Epoch 21/1500\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 0.6090 - accuracy: 0.4164 - val_loss: 0.9254 - val_accuracy: 0.1718\n",
      "Epoch 22/1500\n",
      "126/126 [==============================] - 9s 72ms/step - loss: 0.5923 - accuracy: 0.4385 - val_loss: 0.9180 - val_accuracy: 0.1930\n",
      "Epoch 23/1500\n",
      "126/126 [==============================] - 10s 81ms/step - loss: 0.5717 - accuracy: 0.4493 - val_loss: 0.9191 - val_accuracy: 0.1951\n",
      "Epoch 24/1500\n",
      "126/126 [==============================] - 9s 70ms/step - loss: 0.5540 - accuracy: 0.4642 - val_loss: 0.9258 - val_accuracy: 0.1866\n",
      "Epoch 25/1500\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.5367 - accuracy: 0.4817 - val_loss: 0.9309 - val_accuracy: 0.1803\n",
      "Epoch 26/1500\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 0.5192 - accuracy: 0.5013 - val_loss: 0.9354 - val_accuracy: 0.1983\n",
      "Epoch 27/1500\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.5029 - accuracy: 0.5088 - val_loss: 0.9336 - val_accuracy: 0.2057\n",
      "Epoch 28/1500\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.4897 - accuracy: 0.5180 - val_loss: 0.9414 - val_accuracy: 0.1941\n",
      "Epoch 29/1500\n",
      "126/126 [==============================] - 7s 55ms/step - loss: 0.4731 - accuracy: 0.5382 - val_loss: 0.9428 - val_accuracy: 0.2110\n",
      "Epoch 30/1500\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.4619 - accuracy: 0.5454 - val_loss: 0.9480 - val_accuracy: 0.1994\n",
      "Epoch 31/1500\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.4479 - accuracy: 0.5655 - val_loss: 0.9437 - val_accuracy: 0.2036\n",
      "Epoch 32/1500\n",
      "126/126 [==============================] - 9s 70ms/step - loss: 0.4406 - accuracy: 0.5674 - val_loss: 0.9430 - val_accuracy: 0.1962\n",
      "Epoch 33/1500\n",
      "126/126 [==============================] - 11s 91ms/step - loss: 0.4266 - accuracy: 0.5790 - val_loss: 0.9487 - val_accuracy: 0.1972\n",
      "Epoch 34/1500\n",
      "126/126 [==============================] - 10s 82ms/step - loss: 0.4159 - accuracy: 0.5926 - val_loss: 0.9476 - val_accuracy: 0.1962\n",
      "Epoch 35/1500\n",
      "126/126 [==============================] - 7s 55ms/step - loss: 0.4040 - accuracy: 0.6021 - val_loss: 0.9531 - val_accuracy: 0.2100\n",
      "Epoch 36/1500\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.3954 - accuracy: 0.6151 - val_loss: 0.9559 - val_accuracy: 0.1983\n",
      "Epoch 37/1500\n",
      "126/126 [==============================] - 9s 74ms/step - loss: 0.3842 - accuracy: 0.6117 - val_loss: 0.9568 - val_accuracy: 0.2110\n",
      "Epoch 38/1500\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.3777 - accuracy: 0.6300 - val_loss: 0.9561 - val_accuracy: 0.2153\n",
      "Epoch 39/1500\n",
      "126/126 [==============================] - 9s 69ms/step - loss: 0.3707 - accuracy: 0.6324 - val_loss: 0.9636 - val_accuracy: 0.2015\n",
      "Epoch 40/1500\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 0.3608 - accuracy: 0.6385 - val_loss: 0.9589 - val_accuracy: 0.2025\n",
      "Epoch 41/1500\n",
      "126/126 [==============================] - 9s 69ms/step - loss: 0.3540 - accuracy: 0.6395 - val_loss: 0.9601 - val_accuracy: 0.2089\n",
      "Epoch 42/1500\n",
      "126/126 [==============================] - 9s 74ms/step - loss: 0.3456 - accuracy: 0.6621 - val_loss: 0.9617 - val_accuracy: 0.2100\n",
      "Epoch 43/1500\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.3407 - accuracy: 0.6589 - val_loss: 0.9607 - val_accuracy: 0.2110\n",
      "Epoch 44/1500\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.3357 - accuracy: 0.6703 - val_loss: 0.9587 - val_accuracy: 0.1962\n",
      "Epoch 45/1500\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.3296 - accuracy: 0.6743 - val_loss: 0.9611 - val_accuracy: 0.1941\n",
      "Epoch 46/1500\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.3227 - accuracy: 0.6748 - val_loss: 0.9647 - val_accuracy: 0.1994\n",
      "Epoch 47/1500\n",
      "126/126 [==============================] - 11s 88ms/step - loss: 0.3182 - accuracy: 0.6817 - val_loss: 0.9615 - val_accuracy: 0.1951\n",
      "Epoch 48/1500\n",
      "126/126 [==============================] - 9s 70ms/step - loss: 0.3140 - accuracy: 0.6936 - val_loss: 0.9643 - val_accuracy: 0.1877\n",
      "Epoch 49/1500\n",
      "126/126 [==============================] - 11s 86ms/step - loss: 0.3064 - accuracy: 0.6997 - val_loss: 0.9639 - val_accuracy: 0.2004\n",
      "Epoch 50/1500\n",
      "126/126 [==============================] - 11s 85ms/step - loss: 0.3043 - accuracy: 0.6995 - val_loss: 0.9603 - val_accuracy: 0.1983\n",
      "Epoch 51/1500\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.2991 - accuracy: 0.6979 - val_loss: 0.9637 - val_accuracy: 0.2047\n",
      "Epoch 52/1500\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.2972 - accuracy: 0.7125 - val_loss: 0.9669 - val_accuracy: 0.1919\n",
      "Epoch 53/1500\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 0.2930 - accuracy: 0.7138 - val_loss: 0.9662 - val_accuracy: 0.2004\n",
      "Epoch 54/1500\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.2868 - accuracy: 0.7143 - val_loss: 0.9653 - val_accuracy: 0.1919\n",
      "Epoch 55/1500\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.2855 - accuracy: 0.7162 - val_loss: 0.9647 - val_accuracy: 0.2057\n",
      "Epoch 56/1500\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.2794 - accuracy: 0.7175 - val_loss: 0.9688 - val_accuracy: 0.1856\n",
      "Epoch 57/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 8s 62ms/step - loss: 0.2791 - accuracy: 0.7281 - val_loss: 0.9627 - val_accuracy: 0.1983\n",
      "Epoch 58/1500\n",
      "126/126 [==============================] - 7s 55ms/step - loss: 0.2752 - accuracy: 0.7289 - val_loss: 0.9667 - val_accuracy: 0.1941\n",
      "Epoch 59/1500\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.2717 - accuracy: 0.7326 - val_loss: 0.9651 - val_accuracy: 0.2068\n",
      "Epoch 60/1500\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.2707 - accuracy: 0.7332 - val_loss: 0.9681 - val_accuracy: 0.2036\n",
      "Epoch 61/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.2651 - accuracy: 0.7340 - val_loss: 0.9650 - val_accuracy: 0.1941\n",
      "Epoch 62/1500\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2651 - accuracy: 0.7350 - val_loss: 0.9660 - val_accuracy: 0.1898\n",
      "Epoch 63/1500\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 0.2619 - accuracy: 0.7462 - val_loss: 0.9705 - val_accuracy: 0.1888\n",
      "Epoch 64/1500\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.2590 - accuracy: 0.7621 - val_loss: 0.9692 - val_accuracy: 0.2068\n",
      "Epoch 65/1500\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.2580 - accuracy: 0.7446 - val_loss: 0.9715 - val_accuracy: 0.1962\n",
      "Epoch 66/1500\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.2535 - accuracy: 0.7451 - val_loss: 0.9658 - val_accuracy: 0.1951\n",
      "Epoch 67/1500\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.2522 - accuracy: 0.7525 - val_loss: 0.9665 - val_accuracy: 0.2078\n",
      "Epoch 68/1500\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2494 - accuracy: 0.7560 - val_loss: 0.9685 - val_accuracy: 0.1930\n",
      "Epoch 69/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.2466 - accuracy: 0.7554 - val_loss: 0.9712 - val_accuracy: 0.1972\n",
      "Epoch 70/1500\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.2465 - accuracy: 0.7523 - val_loss: 0.9701 - val_accuracy: 0.1866\n",
      "Epoch 71/1500\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.2412 - accuracy: 0.7692 - val_loss: 0.9707 - val_accuracy: 0.2015\n",
      "Epoch 72/1500\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.2420 - accuracy: 0.7637 - val_loss: 0.9706 - val_accuracy: 0.2131\n",
      "Epoch 73/1500\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.2384 - accuracy: 0.7639 - val_loss: 0.9665 - val_accuracy: 0.2089\n",
      "Epoch 74/1500\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.2380 - accuracy: 0.7655 - val_loss: 0.9617 - val_accuracy: 0.2036\n",
      "Epoch 75/1500\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 0.2368 - accuracy: 0.7682 - val_loss: 0.9664 - val_accuracy: 0.2004\n",
      "Epoch 76/1500\n",
      "126/126 [==============================] - 13s 100ms/step - loss: 0.2364 - accuracy: 0.7716 - val_loss: 0.9623 - val_accuracy: 0.2131\n",
      "Epoch 77/1500\n",
      "126/126 [==============================] - 7s 55ms/step - loss: 0.2342 - accuracy: 0.7719 - val_loss: 0.9636 - val_accuracy: 0.1962\n",
      "Epoch 78/1500\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.2305 - accuracy: 0.7740 - val_loss: 0.9671 - val_accuracy: 0.1983\n",
      "Epoch 79/1500\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.2328 - accuracy: 0.7711 - val_loss: 0.9617 - val_accuracy: 0.2078\n",
      "Epoch 80/1500\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 0.2304 - accuracy: 0.7737 - val_loss: 0.9625 - val_accuracy: 0.2068\n",
      "Epoch 81/1500\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.2288 - accuracy: 0.7745 - val_loss: 0.9677 - val_accuracy: 0.2110\n",
      "Epoch 82/1500\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.2241 - accuracy: 0.7703 - val_loss: 0.9673 - val_accuracy: 0.2089\n",
      "Epoch 83/1500\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.2259 - accuracy: 0.7756 - val_loss: 0.9571 - val_accuracy: 0.2100\n",
      "Epoch 84/1500\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.2225 - accuracy: 0.7968 - val_loss: 0.9666 - val_accuracy: 0.2025\n",
      "Epoch 85/1500\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 0.2203 - accuracy: 0.7830 - val_loss: 0.9634 - val_accuracy: 0.2142\n",
      "Epoch 86/1500\n",
      "126/126 [==============================] - 9s 72ms/step - loss: 0.2210 - accuracy: 0.7825 - val_loss: 0.9628 - val_accuracy: 0.2110\n",
      "Epoch 87/1500\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.2197 - accuracy: 0.7801 - val_loss: 0.9620 - val_accuracy: 0.2057\n",
      "Epoch 88/1500\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.2195 - accuracy: 0.7812 - val_loss: 0.9618 - val_accuracy: 0.1994\n",
      "Epoch 89/1500\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.2173 - accuracy: 0.7806 - val_loss: 0.9614 - val_accuracy: 0.2089\n",
      "Epoch 90/1500\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.2143 - accuracy: 0.7881 - val_loss: 0.9626 - val_accuracy: 0.2142\n",
      "Epoch 91/1500\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.2125 - accuracy: 0.7979 - val_loss: 0.9610 - val_accuracy: 0.2121\n",
      "Epoch 92/1500\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.2146 - accuracy: 0.7989 - val_loss: 0.9623 - val_accuracy: 0.2078\n",
      "Epoch 93/1500\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.2133 - accuracy: 0.7939 - val_loss: 0.9593 - val_accuracy: 0.2110\n",
      "Epoch 94/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.2122 - accuracy: 0.8003 - val_loss: 0.9650 - val_accuracy: 0.2110\n",
      "Epoch 95/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.2112 - accuracy: 0.8027 - val_loss: 0.9640 - val_accuracy: 0.1951\n",
      "Epoch 96/1500\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.2099 - accuracy: 0.8013 - val_loss: 0.9637 - val_accuracy: 0.2036\n",
      "Epoch 97/1500\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.2070 - accuracy: 0.7981 - val_loss: 0.9577 - val_accuracy: 0.1994\n",
      "Epoch 98/1500\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.2094 - accuracy: 0.7976 - val_loss: 0.9665 - val_accuracy: 0.2163\n",
      "Epoch 99/1500\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.2070 - accuracy: 0.8090 - val_loss: 0.9607 - val_accuracy: 0.2131\n",
      "Epoch 100/1500\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.2057 - accuracy: 0.8042 - val_loss: 0.9621 - val_accuracy: 0.2100\n",
      "Epoch 101/1500\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.2044 - accuracy: 0.8156 - val_loss: 0.9636 - val_accuracy: 0.2078\n",
      "Epoch 102/1500\n",
      "126/126 [==============================] - 6s 52ms/step - loss: 0.2008 - accuracy: 0.8106 - val_loss: 0.9609 - val_accuracy: 0.2110\n",
      "Epoch 103/1500\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.2007 - accuracy: 0.8080 - val_loss: 0.9619 - val_accuracy: 0.2110\n",
      "Epoch 104/1500\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.2029 - accuracy: 0.8101 - val_loss: 0.9616 - val_accuracy: 0.2004\n",
      "Epoch 105/1500\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.2003 - accuracy: 0.7987 - val_loss: 0.9627 - val_accuracy: 0.1972\n",
      "Epoch 106/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.2007 - accuracy: 0.8133 - val_loss: 0.9607 - val_accuracy: 0.2216\n",
      "Epoch 107/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.2017 - accuracy: 0.8154 - val_loss: 0.9578 - val_accuracy: 0.2036\n",
      "Epoch 108/1500\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.1997 - accuracy: 0.8085 - val_loss: 0.9594 - val_accuracy: 0.2004\n",
      "Epoch 109/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.2010 - accuracy: 0.8122 - val_loss: 0.9608 - val_accuracy: 0.2185\n",
      "Epoch 110/1500\n",
      "126/126 [==============================] - 5s 42ms/step - loss: 0.1957 - accuracy: 0.8111 - val_loss: 0.9612 - val_accuracy: 0.2036\n",
      "Epoch 111/1500\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.1975 - accuracy: 0.8154 - val_loss: 0.9597 - val_accuracy: 0.2153\n",
      "Epoch 112/1500\n",
      "126/126 [==============================] - 11s 88ms/step - loss: 0.1958 - accuracy: 0.8125 - val_loss: 0.9649 - val_accuracy: 0.1983\n",
      "Epoch 113/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 8s 62ms/step - loss: 0.1941 - accuracy: 0.8199 - val_loss: 0.9628 - val_accuracy: 0.1994\n",
      "Epoch 114/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1972 - accuracy: 0.8183 - val_loss: 0.9622 - val_accuracy: 0.2015\n",
      "Epoch 115/1500\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 0.1951 - accuracy: 0.8164 - val_loss: 0.9621 - val_accuracy: 0.2078\n",
      "Epoch 116/1500\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.1937 - accuracy: 0.8175 - val_loss: 0.9638 - val_accuracy: 0.2036\n",
      "Epoch 117/1500\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.1933 - accuracy: 0.8138 - val_loss: 0.9654 - val_accuracy: 0.2078\n",
      "Epoch 118/1500\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.1914 - accuracy: 0.8122 - val_loss: 0.9640 - val_accuracy: 0.2110\n",
      "Epoch 119/1500\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.1914 - accuracy: 0.8172 - val_loss: 0.9619 - val_accuracy: 0.2110\n",
      "Epoch 120/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1907 - accuracy: 0.8156 - val_loss: 0.9605 - val_accuracy: 0.2089\n",
      "Epoch 121/1500\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1903 - accuracy: 0.8164 - val_loss: 0.9622 - val_accuracy: 0.2068\n",
      "Epoch 122/1500\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.1890 - accuracy: 0.8196 - val_loss: 0.9570 - val_accuracy: 0.2047\n",
      "Epoch 123/1500\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.1886 - accuracy: 0.8244 - val_loss: 0.9608 - val_accuracy: 0.2078\n",
      "Epoch 124/1500\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.1874 - accuracy: 0.8231 - val_loss: 0.9576 - val_accuracy: 0.2078\n",
      "Epoch 125/1500\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.1878 - accuracy: 0.8199 - val_loss: 0.9595 - val_accuracy: 0.2131\n",
      "Epoch 126/1500\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.1874 - accuracy: 0.8196 - val_loss: 0.9592 - val_accuracy: 0.2068\n",
      "Epoch 127/1500\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.1878 - accuracy: 0.8236 - val_loss: 0.9614 - val_accuracy: 0.2110\n",
      "Epoch 128/1500\n",
      "126/126 [==============================] - 7s 55ms/step - loss: 0.1853 - accuracy: 0.8284 - val_loss: 0.9624 - val_accuracy: 0.1983\n",
      "Epoch 129/1500\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.1871 - accuracy: 0.8316 - val_loss: 0.9609 - val_accuracy: 0.2057\n",
      "Epoch 130/1500\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 0.1857 - accuracy: 0.8196 - val_loss: 0.9584 - val_accuracy: 0.2089\n",
      "Epoch 131/1500\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.1830 - accuracy: 0.8281 - val_loss: 0.9609 - val_accuracy: 0.2121\n",
      "Epoch 132/1500\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.1854 - accuracy: 0.8175 - val_loss: 0.9611 - val_accuracy: 0.1983\n",
      "Epoch 133/1500\n",
      "126/126 [==============================] - 7s 60ms/step - loss: 0.1828 - accuracy: 0.8302 - val_loss: 0.9580 - val_accuracy: 0.2153\n",
      "Epoch 134/1500\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.1826 - accuracy: 0.8257 - val_loss: 0.9605 - val_accuracy: 0.2025\n",
      "Epoch 135/1500\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.1836 - accuracy: 0.8212 - val_loss: 0.9565 - val_accuracy: 0.1983\n",
      "Epoch 136/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1808 - accuracy: 0.8395 - val_loss: 0.9557 - val_accuracy: 0.2047\n",
      "Epoch 137/1500\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1806 - accuracy: 0.8241 - val_loss: 0.9563 - val_accuracy: 0.2216\n",
      "Epoch 138/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1826 - accuracy: 0.8239 - val_loss: 0.9596 - val_accuracy: 0.2163\n",
      "Epoch 139/1500\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.1813 - accuracy: 0.8302 - val_loss: 0.9578 - val_accuracy: 0.2195\n",
      "Epoch 140/1500\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.1787 - accuracy: 0.8324 - val_loss: 0.9549 - val_accuracy: 0.2089\n",
      "Epoch 141/1500\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.1800 - accuracy: 0.8284 - val_loss: 0.9574 - val_accuracy: 0.2078\n",
      "Epoch 142/1500\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.1807 - accuracy: 0.8302 - val_loss: 0.9541 - val_accuracy: 0.1994\n",
      "Epoch 143/1500\n",
      "126/126 [==============================] - 5s 42ms/step - loss: 0.1795 - accuracy: 0.8377 - val_loss: 0.9552 - val_accuracy: 0.2078\n",
      "Epoch 144/1500\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.1807 - accuracy: 0.8345 - val_loss: 0.9550 - val_accuracy: 0.2089\n",
      "Epoch 145/1500\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.1782 - accuracy: 0.8202 - val_loss: 0.9555 - val_accuracy: 0.2131\n",
      "Epoch 146/1500\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.1766 - accuracy: 0.8369 - val_loss: 0.9542 - val_accuracy: 0.2089\n",
      "Epoch 147/1500\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.1754 - accuracy: 0.8310 - val_loss: 0.9495 - val_accuracy: 0.2206\n",
      "Epoch 148/1500\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.1766 - accuracy: 0.8210 - val_loss: 0.9507 - val_accuracy: 0.2227\n",
      "Epoch 149/1500\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1750 - accuracy: 0.8347 - val_loss: 0.9558 - val_accuracy: 0.2185\n",
      "Epoch 150/1500\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.1765 - accuracy: 0.8377 - val_loss: 0.9534 - val_accuracy: 0.1972\n",
      "Epoch 151/1500\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.1755 - accuracy: 0.8294 - val_loss: 0.9517 - val_accuracy: 0.2163\n",
      "Epoch 152/1500\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.1737 - accuracy: 0.8424 - val_loss: 0.9533 - val_accuracy: 0.2163\n",
      "Epoch 153/1500\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1733 - accuracy: 0.8332 - val_loss: 0.9523 - val_accuracy: 0.2216\n",
      "Epoch 154/1500\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.1721 - accuracy: 0.8340 - val_loss: 0.9529 - val_accuracy: 0.2057\n",
      "Epoch 155/1500\n",
      "126/126 [==============================] - 5s 42ms/step - loss: 0.1740 - accuracy: 0.8366 - val_loss: 0.9506 - val_accuracy: 0.2078\n",
      "Epoch 156/1500\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.1745 - accuracy: 0.8297 - val_loss: 0.9560 - val_accuracy: 0.2068\n",
      "Epoch 157/1500\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 0.1733 - accuracy: 0.8284 - val_loss: 0.9519 - val_accuracy: 0.2227\n",
      "Epoch 158/1500\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.1723 - accuracy: 0.8440 - val_loss: 0.9554 - val_accuracy: 0.2238\n",
      "Epoch 159/1500\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.1715 - accuracy: 0.8430 - val_loss: 0.9525 - val_accuracy: 0.2195\n",
      "Epoch 160/1500\n",
      "126/126 [==============================] - 5s 42ms/step - loss: 0.1716 - accuracy: 0.8310 - val_loss: 0.9563 - val_accuracy: 0.2269\n",
      "Epoch 161/1500\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1737 - accuracy: 0.8324 - val_loss: 0.9560 - val_accuracy: 0.2142\n",
      "Epoch 162/1500\n",
      "126/126 [==============================] - 10s 77ms/step - loss: 0.1708 - accuracy: 0.8387 - val_loss: 0.9550 - val_accuracy: 0.2195\n",
      "Epoch 163/1500\n",
      "126/126 [==============================] - 10s 78ms/step - loss: 0.1700 - accuracy: 0.8355 - val_loss: 0.9498 - val_accuracy: 0.1972\n",
      "Epoch 164/1500\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.1710 - accuracy: 0.8302 - val_loss: 0.9534 - val_accuracy: 0.2153\n",
      "Epoch 165/1500\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.1707 - accuracy: 0.8313 - val_loss: 0.9538 - val_accuracy: 0.2004\n",
      "Epoch 166/1500\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.1708 - accuracy: 0.8284 - val_loss: 0.9501 - val_accuracy: 0.2185\n",
      "Epoch 167/1500\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1690 - accuracy: 0.8432 - val_loss: 0.9550 - val_accuracy: 0.1994\n",
      "Epoch 168/1500\n",
      "126/126 [==============================] - 11s 86ms/step - loss: 0.1697 - accuracy: 0.8305 - val_loss: 0.9548 - val_accuracy: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1500\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.1676 - accuracy: 0.8424 - val_loss: 0.9488 - val_accuracy: 0.2174\n",
      "Epoch 170/1500\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.1684 - accuracy: 0.8501 - val_loss: 0.9510 - val_accuracy: 0.2163\n",
      "Epoch 171/1500\n",
      "126/126 [==============================] - 7s 55ms/step - loss: 0.1667 - accuracy: 0.8366 - val_loss: 0.9509 - val_accuracy: 0.2280\n",
      "Epoch 172/1500\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1671 - accuracy: 0.8411 - val_loss: 0.9501 - val_accuracy: 0.2036\n",
      "Epoch 173/1500\n",
      "126/126 [==============================] - 9s 69ms/step - loss: 0.1665 - accuracy: 0.8379 - val_loss: 0.9524 - val_accuracy: 0.2174\n",
      "Epoch 174/1500\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.1668 - accuracy: 0.8337 - val_loss: 0.9521 - val_accuracy: 0.1994\n",
      "Epoch 175/1500\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.1661 - accuracy: 0.8443 - val_loss: 0.9535 - val_accuracy: 0.2110\n",
      "Epoch 176/1500\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.1672 - accuracy: 0.8454 - val_loss: 0.9510 - val_accuracy: 0.2110\n",
      "Epoch 177/1500\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.1650 - accuracy: 0.8369 - val_loss: 0.9496 - val_accuracy: 0.2100\n",
      "Epoch 178/1500\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 0.1662 - accuracy: 0.8462 - val_loss: 0.9525 - val_accuracy: 0.2121\n",
      "Epoch 179/1500\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 0.1661 - accuracy: 0.8477 - val_loss: 0.9520 - val_accuracy: 0.2206\n",
      "Epoch 180/1500\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.1645 - accuracy: 0.8483 - val_loss: 0.9494 - val_accuracy: 0.2110\n",
      "Epoch 181/1500\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.1646 - accuracy: 0.8353 - val_loss: 0.9491 - val_accuracy: 0.2206\n",
      "Epoch 182/1500\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1644 - accuracy: 0.8512 - val_loss: 0.9443 - val_accuracy: 0.2110\n",
      "Epoch 183/1500\n",
      "126/126 [==============================] - 12s 94ms/step - loss: 0.1658 - accuracy: 0.8300 - val_loss: 0.9466 - val_accuracy: 0.2121\n",
      "Epoch 184/1500\n",
      "126/126 [==============================] - 10s 77ms/step - loss: 0.1636 - accuracy: 0.8464 - val_loss: 0.9516 - val_accuracy: 0.2089\n",
      "Epoch 185/1500\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.1635 - accuracy: 0.8507 - val_loss: 0.9508 - val_accuracy: 0.2078\n",
      "Epoch 186/1500\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.1626 - accuracy: 0.8435 - val_loss: 0.9507 - val_accuracy: 0.2068\n",
      "Epoch 187/1500\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.1641 - accuracy: 0.8408 - val_loss: 0.9509 - val_accuracy: 0.2057\n",
      "Epoch 188/1500\n",
      "126/126 [==============================] - 10s 76ms/step - loss: 0.1626 - accuracy: 0.8491 - val_loss: 0.9502 - val_accuracy: 0.2025\n",
      "Epoch 189/1500\n",
      "126/126 [==============================] - 10s 78ms/step - loss: 0.1628 - accuracy: 0.8477 - val_loss: 0.9506 - val_accuracy: 0.2153\n",
      "Epoch 190/1500\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.1620 - accuracy: 0.8385 - val_loss: 0.9510 - val_accuracy: 0.2163\n",
      "Epoch 191/1500\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.1630 - accuracy: 0.8544 - val_loss: 0.9502 - val_accuracy: 0.2089\n",
      "Epoch 192/1500\n",
      "126/126 [==============================] - 9s 70ms/step - loss: 0.1620 - accuracy: 0.8424 - val_loss: 0.9502 - val_accuracy: 0.2036\n",
      "Epoch 193/1500\n",
      "126/126 [==============================] - 9s 71ms/step - loss: 0.1607 - accuracy: 0.8448 - val_loss: 0.9483 - val_accuracy: 0.2121\n",
      "Epoch 194/1500\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.1597 - accuracy: 0.8464 - val_loss: 0.9508 - val_accuracy: 0.2185\n",
      "Epoch 195/1500\n",
      "126/126 [==============================] - 10s 76ms/step - loss: 0.1620 - accuracy: 0.8416 - val_loss: 0.9478 - val_accuracy: 0.2153\n",
      "Epoch 196/1500\n",
      "126/126 [==============================] - 10s 81ms/step - loss: 0.1599 - accuracy: 0.8568 - val_loss: 0.9483 - val_accuracy: 0.2036\n",
      "Epoch 197/1500\n",
      "126/126 [==============================] - 14s 114ms/step - loss: 0.1608 - accuracy: 0.8517 - val_loss: 0.9488 - val_accuracy: 0.2163\n",
      "Epoch 198/1500\n",
      "126/126 [==============================] - 14s 113ms/step - loss: 0.1594 - accuracy: 0.8382 - val_loss: 0.9486 - val_accuracy: 0.2121\n",
      "Epoch 199/1500\n",
      "126/126 [==============================] - 13s 107ms/step - loss: 0.1594 - accuracy: 0.8562 - val_loss: 0.9515 - val_accuracy: 0.2078\n",
      "Epoch 200/1500\n",
      "126/126 [==============================] - 12s 93ms/step - loss: 0.1585 - accuracy: 0.8464 - val_loss: 0.9500 - val_accuracy: 0.2142\n",
      "Epoch 201/1500\n",
      "126/126 [==============================] - 11s 89ms/step - loss: 0.1593 - accuracy: 0.8446 - val_loss: 0.9477 - val_accuracy: 0.1972\n",
      "Epoch 202/1500\n",
      "126/126 [==============================] - 9s 74ms/step - loss: 0.1595 - accuracy: 0.8485 - val_loss: 0.9470 - val_accuracy: 0.2142\n",
      "Epoch 203/1500\n",
      "126/126 [==============================] - 10s 76ms/step - loss: 0.1592 - accuracy: 0.8451 - val_loss: 0.9465 - val_accuracy: 0.2153\n",
      "Epoch 204/1500\n",
      "126/126 [==============================] - 11s 89ms/step - loss: 0.1584 - accuracy: 0.8531 - val_loss: 0.9455 - val_accuracy: 0.2142\n",
      "Epoch 205/1500\n",
      "126/126 [==============================] - 10s 81ms/step - loss: 0.1603 - accuracy: 0.8424 - val_loss: 0.9460 - val_accuracy: 0.2089\n",
      "Epoch 206/1500\n",
      "126/126 [==============================] - 9s 72ms/step - loss: 0.1566 - accuracy: 0.8491 - val_loss: 0.9471 - val_accuracy: 0.2100\n",
      "Epoch 207/1500\n",
      "126/126 [==============================] - 9s 68ms/step - loss: 0.1562 - accuracy: 0.8499 - val_loss: 0.9477 - val_accuracy: 0.2131\n",
      "Epoch 208/1500\n",
      "126/126 [==============================] - 9s 72ms/step - loss: 0.1571 - accuracy: 0.8501 - val_loss: 0.9479 - val_accuracy: 0.2153\n",
      "Epoch 209/1500\n",
      "126/126 [==============================] - 10s 76ms/step - loss: 0.1563 - accuracy: 0.8483 - val_loss: 0.9479 - val_accuracy: 0.2195\n",
      "Epoch 210/1500\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.1588 - accuracy: 0.8562 - val_loss: 0.9432 - val_accuracy: 0.2047\n",
      "Epoch 211/1500\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.1565 - accuracy: 0.8483 - val_loss: 0.9478 - val_accuracy: 0.2078\n",
      "Epoch 212/1500\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.1563 - accuracy: 0.8538 - val_loss: 0.9455 - val_accuracy: 0.2036\n",
      "Epoch 213/1500\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.1556 - accuracy: 0.8525 - val_loss: 0.9471 - val_accuracy: 0.2238\n",
      "Epoch 214/1500\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.1566 - accuracy: 0.8554 - val_loss: 0.9460 - val_accuracy: 0.2100\n",
      "Epoch 215/1500\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.1556 - accuracy: 0.8660 - val_loss: 0.9466 - val_accuracy: 0.2195\n",
      "Epoch 216/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1543 - accuracy: 0.8499 - val_loss: 0.9440 - val_accuracy: 0.2163\n",
      "Epoch 217/1500\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.1554 - accuracy: 0.8573 - val_loss: 0.9436 - val_accuracy: 0.2131\n",
      "Epoch 218/1500\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.1543 - accuracy: 0.8528 - val_loss: 0.9417 - val_accuracy: 0.2057\n",
      "Epoch 219/1500\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.1555 - accuracy: 0.8427 - val_loss: 0.9429 - val_accuracy: 0.2174\n",
      "Epoch 220/1500\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.1565 - accuracy: 0.8586 - val_loss: 0.9442 - val_accuracy: 0.2121\n",
      "Epoch 221/1500\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.1537 - accuracy: 0.8531 - val_loss: 0.9448 - val_accuracy: 0.2163\n",
      "Epoch 222/1500\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 0.1516 - accuracy: 0.8610 - val_loss: 0.9469 - val_accuracy: 0.2100\n",
      "Epoch 223/1500\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.1528 - accuracy: 0.8472 - val_loss: 0.9421 - val_accuracy: 0.2089\n",
      "Epoch 224/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 6s 48ms/step - loss: 0.1536 - accuracy: 0.8533 - val_loss: 0.9476 - val_accuracy: 0.2078\n",
      "Epoch 225/1500\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.1527 - accuracy: 0.8573 - val_loss: 0.9427 - val_accuracy: 0.2174\n",
      "Epoch 226/1500\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.1537 - accuracy: 0.8432 - val_loss: 0.9465 - val_accuracy: 0.2100\n",
      "Epoch 227/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1526 - accuracy: 0.8653 - val_loss: 0.9467 - val_accuracy: 0.2121\n",
      "Epoch 228/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1530 - accuracy: 0.8538 - val_loss: 0.9419 - val_accuracy: 0.2121\n",
      "Epoch 229/1500\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1535 - accuracy: 0.8544 - val_loss: 0.9404 - val_accuracy: 0.2142\n",
      "Epoch 230/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1524 - accuracy: 0.8538 - val_loss: 0.9422 - val_accuracy: 0.2100\n",
      "Epoch 231/1500\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.1532 - accuracy: 0.8515 - val_loss: 0.9431 - val_accuracy: 0.1951\n",
      "Epoch 232/1500\n",
      "126/126 [==============================] - 5s 39ms/step - loss: 0.1535 - accuracy: 0.8552 - val_loss: 0.9448 - val_accuracy: 0.2153\n",
      "Epoch 233/1500\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.1521 - accuracy: 0.8541 - val_loss: 0.9442 - val_accuracy: 0.2100\n",
      "Epoch 234/1500\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1519 - accuracy: 0.8631 - val_loss: 0.9437 - val_accuracy: 0.2100\n",
      "Epoch 235/1500\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.1532 - accuracy: 0.8594 - val_loss: 0.9418 - val_accuracy: 0.2174\n",
      "Epoch 236/1500\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.1517 - accuracy: 0.8531 - val_loss: 0.9419 - val_accuracy: 0.2153\n",
      "Epoch 237/1500\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.1496 - accuracy: 0.8538 - val_loss: 0.9443 - val_accuracy: 0.1994\n",
      "Epoch 238/1500\n",
      "126/126 [==============================] - 5s 40ms/step - loss: 0.1513 - accuracy: 0.8602 - val_loss: 0.9430 - val_accuracy: 0.2238\n",
      "Epoch 239/1500\n",
      "126/126 [==============================] - 6s 52ms/step - loss: 0.1496 - accuracy: 0.8605 - val_loss: 0.9449 - val_accuracy: 0.2142\n",
      "Epoch 240/1500\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 0.1500 - accuracy: 0.8623 - val_loss: 0.9435 - val_accuracy: 0.2163\n",
      "Epoch 241/1500\n",
      "126/126 [==============================] - 7s 55ms/step - loss: 0.1514 - accuracy: 0.8499 - val_loss: 0.9407 - val_accuracy: 0.2142\n",
      "Epoch 242/1500\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1493 - accuracy: 0.8509 - val_loss: 0.9463 - val_accuracy: 0.2110\n",
      "Epoch 243/1500\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1517 - accuracy: 0.8560 - val_loss: 0.9428 - val_accuracy: 0.2131\n",
      "Epoch 244/1500\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1496 - accuracy: 0.8584 - val_loss: 0.9418 - val_accuracy: 0.2068\n",
      "Epoch 245/1500\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1488 - accuracy: 0.8568 - val_loss: 0.9403 - val_accuracy: 0.2036\n",
      "Epoch 246/1500\n",
      "126/126 [==============================] - 5s 42ms/step - loss: 0.1469 - accuracy: 0.8660 - val_loss: 0.9392 - val_accuracy: 0.2089\n",
      "Epoch 247/1500\n",
      "126/126 [==============================] - 5s 42ms/step - loss: 0.1501 - accuracy: 0.8501 - val_loss: 0.9394 - val_accuracy: 0.2057\n",
      "Epoch 248/1500\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1502 - accuracy: 0.8499 - val_loss: 0.9417 - val_accuracy: 0.2057\n",
      "Epoch 249/1500\n",
      "126/126 [==============================] - 5s 39ms/step - loss: 0.1489 - accuracy: 0.8647 - val_loss: 0.9387 - val_accuracy: 0.2089\n",
      "Epoch 250/1500\n",
      "126/126 [==============================] - 5s 38ms/step - loss: 0.1484 - accuracy: 0.8552 - val_loss: 0.9426 - val_accuracy: 0.2121\n",
      "Epoch 251/1500\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.1497 - accuracy: 0.8531 - val_loss: 0.9430 - val_accuracy: 0.2047\n",
      "Epoch 252/1500\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1482 - accuracy: 0.8629 - val_loss: 0.9417 - val_accuracy: 0.2110\n",
      "Epoch 253/1500\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.1488 - accuracy: 0.8523 - val_loss: 0.9467 - val_accuracy: 0.1951\n",
      "Epoch 254/1500\n",
      "126/126 [==============================] - 12s 92ms/step - loss: 0.1474 - accuracy: 0.8568 - val_loss: 0.9401 - val_accuracy: 0.2100\n",
      "Epoch 255/1500\n",
      "126/126 [==============================] - 10s 83ms/step - loss: 0.1470 - accuracy: 0.8533 - val_loss: 0.9446 - val_accuracy: 0.1930\n",
      "Epoch 256/1500\n",
      "126/126 [==============================] - 9s 72ms/step - loss: 0.1478 - accuracy: 0.8698 - val_loss: 0.9435 - val_accuracy: 0.1983\n",
      "Epoch 257/1500\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.1471 - accuracy: 0.8668 - val_loss: 0.9447 - val_accuracy: 0.2121\n",
      "Epoch 258/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1475 - accuracy: 0.8499 - val_loss: 0.9407 - val_accuracy: 0.2131\n",
      "Epoch 259/1500\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.1480 - accuracy: 0.8586 - val_loss: 0.9440 - val_accuracy: 0.2047\n",
      "Epoch 260/1500\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1469 - accuracy: 0.8586 - val_loss: 0.9435 - val_accuracy: 0.2057\n",
      "Epoch 261/1500\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.1475 - accuracy: 0.8552 - val_loss: 0.9406 - val_accuracy: 0.2004\n",
      "Epoch 262/1500\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.1485 - accuracy: 0.8549 - val_loss: 0.9423 - val_accuracy: 0.2131\n",
      "Epoch 263/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1460 - accuracy: 0.8560 - val_loss: 0.9391 - val_accuracy: 0.1919\n",
      "Epoch 264/1500\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.1469 - accuracy: 0.8507 - val_loss: 0.9428 - val_accuracy: 0.2100\n",
      "Epoch 265/1500\n",
      "126/126 [==============================] - 5s 42ms/step - loss: 0.1463 - accuracy: 0.8599 - val_loss: 0.9425 - val_accuracy: 0.2163\n",
      "Epoch 266/1500\n",
      "126/126 [==============================] - 5s 38ms/step - loss: 0.1441 - accuracy: 0.8753 - val_loss: 0.9418 - val_accuracy: 0.1972\n",
      "Epoch 267/1500\n",
      "126/126 [==============================] - 5s 39ms/step - loss: 0.1457 - accuracy: 0.8607 - val_loss: 0.9419 - val_accuracy: 0.2068\n",
      "Epoch 268/1500\n",
      "126/126 [==============================] - 5s 40ms/step - loss: 0.1461 - accuracy: 0.8536 - val_loss: 0.9410 - val_accuracy: 0.1972\n",
      "Epoch 269/1500\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.1449 - accuracy: 0.8576 - val_loss: 0.9427 - val_accuracy: 0.1994\n",
      "Epoch 270/1500\n",
      "126/126 [==============================] - 7s 55ms/step - loss: 0.1444 - accuracy: 0.8610 - val_loss: 0.9436 - val_accuracy: 0.2057\n",
      "Epoch 271/1500\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.1466 - accuracy: 0.8597 - val_loss: 0.9426 - val_accuracy: 0.1951\n",
      "Epoch 272/1500\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1448 - accuracy: 0.8653 - val_loss: 0.9378 - val_accuracy: 0.1909\n",
      "Epoch 273/1500\n",
      "126/126 [==============================] - 9s 69ms/step - loss: 0.1446 - accuracy: 0.8573 - val_loss: 0.9432 - val_accuracy: 0.2036\n",
      "Epoch 274/1500\n",
      "126/126 [==============================] - 9s 67ms/step - loss: 0.1462 - accuracy: 0.8658 - val_loss: 0.9416 - val_accuracy: 0.1972\n",
      "Epoch 275/1500\n",
      "126/126 [==============================] - 9s 73ms/step - loss: 0.1464 - accuracy: 0.8528 - val_loss: 0.9434 - val_accuracy: 0.2004\n",
      "Epoch 276/1500\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1455 - accuracy: 0.8613 - val_loss: 0.9407 - val_accuracy: 0.2057\n",
      "Epoch 277/1500\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.1440 - accuracy: 0.8658 - val_loss: 0.9385 - val_accuracy: 0.1994\n",
      "Epoch 278/1500\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.1446 - accuracy: 0.8560 - val_loss: 0.9392 - val_accuracy: 0.1962\n",
      "Epoch 279/1500\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.1444 - accuracy: 0.8592 - val_loss: 0.9424 - val_accuracy: 0.1930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1500\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.1450 - accuracy: 0.8570 - val_loss: 0.9443 - val_accuracy: 0.1983\n",
      "Epoch 281/1500\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.1442 - accuracy: 0.8615 - val_loss: 0.9435 - val_accuracy: 0.2036\n",
      "Epoch 282/1500\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.1442 - accuracy: 0.8645 - val_loss: 0.9423 - val_accuracy: 0.2004\n",
      "Epoch 283/1500\n",
      "126/126 [==============================] - 5s 42ms/step - loss: 0.1440 - accuracy: 0.8668 - val_loss: 0.9413 - val_accuracy: 0.2025\n",
      "Epoch 284/1500\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.1456 - accuracy: 0.8706 - val_loss: 0.9443 - val_accuracy: 0.2015\n",
      "Epoch 285/1500\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1424 - accuracy: 0.8618 - val_loss: 0.9418 - val_accuracy: 0.1983\n",
      "Epoch 286/1500\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1431 - accuracy: 0.8554 - val_loss: 0.9416 - val_accuracy: 0.2036\n",
      "Epoch 287/1500\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 0.1437 - accuracy: 0.8629 - val_loss: 0.9405 - val_accuracy: 0.2025\n",
      "Epoch 288/1500\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.1409 - accuracy: 0.8714 - val_loss: 0.9434 - val_accuracy: 0.2100\n",
      "Epoch 289/1500\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 0.1406 - accuracy: 0.8637 - val_loss: 0.9402 - val_accuracy: 0.1962\n",
      "Epoch 290/1500\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 0.1434 - accuracy: 0.8660 - val_loss: 0.9388 - val_accuracy: 0.2153\n",
      "Epoch 291/1500\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.1431 - accuracy: 0.8592 - val_loss: 0.9396 - val_accuracy: 0.2025\n",
      "Epoch 292/1500\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1426 - accuracy: 0.8589 - val_loss: 0.9431 - val_accuracy: 0.2015\n",
      "Epoch 293/1500\n",
      "126/126 [==============================] - 9s 69ms/step - loss: 0.1426 - accuracy: 0.8631 - val_loss: 0.9454 - val_accuracy: 0.1951\n",
      "Epoch 294/1500\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1421 - accuracy: 0.8658 - val_loss: 0.9424 - val_accuracy: 0.1888\n",
      "Epoch 295/1500\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1415 - accuracy: 0.8732 - val_loss: 0.9446 - val_accuracy: 0.1994\n",
      "Epoch 296/1500\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1432 - accuracy: 0.8737 - val_loss: 0.9414 - val_accuracy: 0.2025\n",
      "Epoch 297/1500\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1419 - accuracy: 0.8607 - val_loss: 0.9413 - val_accuracy: 0.1962\n",
      "Epoch 298/1500\n",
      "126/126 [==============================] - 10s 77ms/step - loss: 0.1407 - accuracy: 0.8727 - val_loss: 0.9418 - val_accuracy: 0.2015\n",
      "Epoch 299/1500\n",
      "126/126 [==============================] - 6s 50ms/step - loss: 0.1405 - accuracy: 0.8700 - val_loss: 0.9415 - val_accuracy: 0.2068\n",
      "Epoch 300/1500\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1397 - accuracy: 0.8721 - val_loss: 0.9433 - val_accuracy: 0.2047\n",
      "Epoch 301/1500\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.1420 - accuracy: 0.8714 - val_loss: 0.9394 - val_accuracy: 0.2015\n",
      "Epoch 302/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1397 - accuracy: 0.8660 - val_loss: 0.9395 - val_accuracy: 0.2089\n",
      "Epoch 303/1500\n",
      "126/126 [==============================] - 5s 39ms/step - loss: 0.1409 - accuracy: 0.8700 - val_loss: 0.9416 - val_accuracy: 0.2078\n",
      "Epoch 304/1500\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 0.1409 - accuracy: 0.8721 - val_loss: 0.9396 - val_accuracy: 0.2068\n",
      "Epoch 305/1500\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1395 - accuracy: 0.8676 - val_loss: 0.9437 - val_accuracy: 0.2025\n",
      "Epoch 306/1500\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.1404 - accuracy: 0.8639 - val_loss: 0.9411 - val_accuracy: 0.2015\n",
      "Epoch 307/1500\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.1394 - accuracy: 0.8637 - val_loss: 0.9397 - val_accuracy: 0.2047\n",
      "Epoch 308/1500\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.1401 - accuracy: 0.8764 - val_loss: 0.9369 - val_accuracy: 0.1951\n",
      "Epoch 309/1500\n",
      "126/126 [==============================] - 9s 73ms/step - loss: 0.1408 - accuracy: 0.8631 - val_loss: 0.9405 - val_accuracy: 0.1951\n",
      "Epoch 310/1500\n",
      "126/126 [==============================] - 9s 72ms/step - loss: 0.1405 - accuracy: 0.8605 - val_loss: 0.9406 - val_accuracy: 0.2047\n",
      "Epoch 311/1500\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.1388 - accuracy: 0.8700 - val_loss: 0.9404 - val_accuracy: 0.2068\n",
      "Epoch 312/1500\n",
      "126/126 [==============================] - 7s 60ms/step - loss: 0.1404 - accuracy: 0.8541 - val_loss: 0.9422 - val_accuracy: 0.2004\n",
      "Epoch 313/1500\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.1396 - accuracy: 0.8727 - val_loss: 0.9409 - val_accuracy: 0.2078\n",
      "Epoch 314/1500\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.1387 - accuracy: 0.8690 - val_loss: 0.9410 - val_accuracy: 0.1941\n",
      "Epoch 315/1500\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1393 - accuracy: 0.8682 - val_loss: 0.9397 - val_accuracy: 0.1994\n",
      "Epoch 316/1500\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 0.1394 - accuracy: 0.8682 - val_loss: 0.9388 - val_accuracy: 0.2036\n",
      "Epoch 317/1500\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.1393 - accuracy: 0.8613 - val_loss: 0.9413 - val_accuracy: 0.2025\n",
      "Epoch 318/1500\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1384 - accuracy: 0.8684 - val_loss: 0.9391 - val_accuracy: 0.1941\n",
      "Epoch 319/1500\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 0.1382 - accuracy: 0.8748 - val_loss: 0.9408 - val_accuracy: 0.1994\n",
      "Epoch 320/1500\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.1391 - accuracy: 0.8658 - val_loss: 0.9401 - val_accuracy: 0.1994\n",
      "Epoch 321/1500\n",
      "126/126 [==============================] - 6s 46ms/step - loss: 0.1381 - accuracy: 0.8743 - val_loss: 0.9411 - val_accuracy: 0.1983\n",
      "Epoch 322/1500\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.1381 - accuracy: 0.8676 - val_loss: 0.9415 - val_accuracy: 0.1898\n",
      "Epoch 323/1500\n",
      "126/126 [==============================] - 6s 44ms/step - loss: 0.1384 - accuracy: 0.8660 - val_loss: 0.9377 - val_accuracy: 0.2047\n",
      "Epoch 324/1500\n",
      "126/126 [==============================] - 8s 66ms/step - loss: 0.1387 - accuracy: 0.8706 - val_loss: 0.9384 - val_accuracy: 0.2057\n",
      "Epoch 325/1500\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.1388 - accuracy: 0.8772 - val_loss: 0.9368 - val_accuracy: 0.2068\n",
      "Epoch 326/1500\n",
      "126/126 [==============================] - 8s 63ms/step - loss: 0.1379 - accuracy: 0.8716 - val_loss: 0.9370 - val_accuracy: 0.1994\n",
      "Epoch 327/1500\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.1377 - accuracy: 0.8668 - val_loss: 0.9436 - val_accuracy: 0.2057\n",
      "Epoch 328/1500\n",
      "126/126 [==============================] - 8s 67ms/step - loss: 0.1372 - accuracy: 0.8698 - val_loss: 0.9395 - val_accuracy: 0.2025\n",
      "Epoch 329/1500\n",
      "126/126 [==============================] - 9s 73ms/step - loss: 0.1363 - accuracy: 0.8714 - val_loss: 0.9394 - val_accuracy: 0.1994\n",
      "Epoch 330/1500\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.1367 - accuracy: 0.8700 - val_loss: 0.9402 - val_accuracy: 0.1930\n",
      "Epoch 331/1500\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.1381 - accuracy: 0.8684 - val_loss: 0.9384 - val_accuracy: 0.2078\n",
      "Epoch 332/1500\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.1372 - accuracy: 0.8687 - val_loss: 0.9385 - val_accuracy: 0.1930\n",
      "Epoch 333/1500\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1380 - accuracy: 0.8666 - val_loss: 0.9393 - val_accuracy: 0.2047\n",
      "Epoch 334/1500\n",
      "126/126 [==============================] - 8s 64ms/step - loss: 0.1374 - accuracy: 0.8682 - val_loss: 0.9411 - val_accuracy: 0.1888\n",
      "Epoch 335/1500\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 0.1372 - accuracy: 0.8698 - val_loss: 0.9392 - val_accuracy: 0.2057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/1500\n",
      "126/126 [==============================] - 5s 42ms/step - loss: 0.1373 - accuracy: 0.8570 - val_loss: 0.9372 - val_accuracy: 0.1877\n",
      "Epoch 337/1500\n",
      "126/126 [==============================] - 7s 53ms/step - loss: 0.1363 - accuracy: 0.8745 - val_loss: 0.9389 - val_accuracy: 0.2068\n",
      "Epoch 338/1500\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1377 - accuracy: 0.8711 - val_loss: 0.9409 - val_accuracy: 0.1972\n",
      "Epoch 339/1500\n",
      "126/126 [==============================] - 7s 52ms/step - loss: 0.1363 - accuracy: 0.8650 - val_loss: 0.9394 - val_accuracy: 0.1962\n",
      "Epoch 340/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1377 - accuracy: 0.8700 - val_loss: 0.9394 - val_accuracy: 0.2025\n",
      "Epoch 341/1500\n",
      "126/126 [==============================] - 7s 57ms/step - loss: 0.1366 - accuracy: 0.8764 - val_loss: 0.9412 - val_accuracy: 0.2057\n",
      "Epoch 342/1500\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.1348 - accuracy: 0.8782 - val_loss: 0.9399 - val_accuracy: 0.2121\n",
      "Epoch 343/1500\n",
      "126/126 [==============================] - 9s 74ms/step - loss: 0.1353 - accuracy: 0.8745 - val_loss: 0.9396 - val_accuracy: 0.2078\n",
      "Epoch 344/1500\n",
      "126/126 [==============================] - 7s 56ms/step - loss: 0.1358 - accuracy: 0.8668 - val_loss: 0.9416 - val_accuracy: 0.1866\n",
      "Epoch 345/1500\n",
      "126/126 [==============================] - 7s 59ms/step - loss: 0.1350 - accuracy: 0.8682 - val_loss: 0.9427 - val_accuracy: 0.2025\n",
      "Epoch 346/1500\n",
      "126/126 [==============================] - 8s 65ms/step - loss: 0.1367 - accuracy: 0.8692 - val_loss: 0.9425 - val_accuracy: 0.1898\n",
      "Epoch 347/1500\n",
      "126/126 [==============================] - 12s 93ms/step - loss: 0.1337 - accuracy: 0.8711 - val_loss: 0.9420 - val_accuracy: 0.1962\n",
      "Epoch 348/1500\n",
      "126/126 [==============================] - 10s 83ms/step - loss: 0.1348 - accuracy: 0.8737 - val_loss: 0.9427 - val_accuracy: 0.1972\n",
      "Epoch 349/1500\n",
      "126/126 [==============================] - 10s 76ms/step - loss: 0.1356 - accuracy: 0.8777 - val_loss: 0.9396 - val_accuracy: 0.1994\n",
      "Epoch 350/1500\n",
      "126/126 [==============================] - 6s 48ms/step - loss: 0.1363 - accuracy: 0.8674 - val_loss: 0.9415 - val_accuracy: 0.1941\n",
      "Epoch 351/1500\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.1350 - accuracy: 0.8645 - val_loss: 0.9417 - val_accuracy: 0.1951\n",
      "Epoch 352/1500\n",
      "126/126 [==============================] - 7s 58ms/step - loss: 0.1359 - accuracy: 0.8703 - val_loss: 0.9411 - val_accuracy: 0.1898\n",
      "Epoch 353/1500\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1340 - accuracy: 0.8806 - val_loss: 0.9410 - val_accuracy: 0.1972\n",
      "Epoch 354/1500\n",
      "126/126 [==============================] - 6s 49ms/step - loss: 0.1360 - accuracy: 0.8714 - val_loss: 0.9401 - val_accuracy: 0.2025\n",
      "Epoch 355/1500\n",
      "126/126 [==============================] - 5s 43ms/step - loss: 0.1353 - accuracy: 0.8740 - val_loss: 0.9439 - val_accuracy: 0.1962\n",
      "Epoch 356/1500\n",
      "126/126 [==============================] - 7s 54ms/step - loss: 0.1358 - accuracy: 0.8740 - val_loss: 0.9434 - val_accuracy: 0.1898\n",
      "Epoch 357/1500\n",
      "126/126 [==============================] - 7s 55ms/step - loss: 0.1344 - accuracy: 0.8690 - val_loss: 0.9446 - val_accuracy: 0.1845\n",
      "Epoch 358/1500\n",
      "126/126 [==============================] - 5s 36ms/step - loss: 0.1349 - accuracy: 0.8806 - val_loss: 0.9448 - val_accuracy: 0.1951\n",
      "Epoch 359/1500\n",
      "126/126 [==============================] - 4s 34ms/step - loss: 0.1347 - accuracy: 0.8706 - val_loss: 0.9426 - val_accuracy: 0.2015\n",
      "Epoch 360/1500\n",
      "126/126 [==============================] - 5s 40ms/step - loss: 0.1357 - accuracy: 0.8695 - val_loss: 0.9423 - val_accuracy: 0.1972\n",
      "Epoch 361/1500\n",
      "126/126 [==============================] - 5s 38ms/step - loss: 0.1321 - accuracy: 0.8764 - val_loss: 0.9420 - val_accuracy: 0.1983\n",
      "Epoch 362/1500\n",
      "126/126 [==============================] - 5s 39ms/step - loss: 0.1345 - accuracy: 0.8830 - val_loss: 0.9429 - val_accuracy: 0.2068\n",
      "Epoch 363/1500\n",
      "126/126 [==============================] - 6s 47ms/step - loss: 0.1344 - accuracy: 0.8655 - val_loss: 0.9432 - val_accuracy: 0.2004\n",
      "Epoch 364/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1350 - accuracy: 0.8812 - val_loss: 0.9400 - val_accuracy: 0.1951\n",
      "Epoch 365/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1346 - accuracy: 0.8618 - val_loss: 0.9445 - val_accuracy: 0.1962\n",
      "Epoch 366/1500\n",
      "126/126 [==============================] - 7s 51ms/step - loss: 0.1335 - accuracy: 0.8753 - val_loss: 0.9436 - val_accuracy: 0.1919\n",
      "Epoch 367/1500\n",
      "126/126 [==============================] - 5s 44ms/step - loss: 0.1336 - accuracy: 0.8668 - val_loss: 0.9397 - val_accuracy: 0.2036\n",
      "Epoch 368/1500\n",
      "126/126 [==============================] - 5s 38ms/step - loss: 0.1328 - accuracy: 0.8676 - val_loss: 0.9419 - val_accuracy: 0.1972\n",
      "Epoch 369/1500\n",
      "126/126 [==============================] - 6s 51ms/step - loss: 0.1332 - accuracy: 0.8706 - val_loss: 0.9371 - val_accuracy: 0.1983\n",
      "Epoch 370/1500\n",
      "126/126 [==============================] - 5s 40ms/step - loss: 0.1342 - accuracy: 0.8759 - val_loss: 0.9397 - val_accuracy: 0.1972\n",
      "Epoch 371/1500\n",
      "126/126 [==============================] - 5s 42ms/step - loss: 0.1338 - accuracy: 0.8769 - val_loss: 0.9414 - val_accuracy: 0.1930\n",
      "Epoch 372/1500\n",
      "126/126 [==============================] - 5s 38ms/step - loss: 0.1333 - accuracy: 0.8735 - val_loss: 0.9398 - val_accuracy: 0.1930\n",
      "Epoch 373/1500\n",
      "126/126 [==============================] - 5s 40ms/step - loss: 0.1340 - accuracy: 0.8769 - val_loss: 0.9413 - val_accuracy: 0.2089\n",
      "Epoch 374/1500\n",
      "126/126 [==============================] - 5s 37ms/step - loss: 0.1337 - accuracy: 0.8695 - val_loss: 0.9415 - val_accuracy: 0.2004\n",
      "Epoch 375/1500\n",
      "126/126 [==============================] - 5s 36ms/step - loss: 0.1330 - accuracy: 0.8682 - val_loss: 0.9429 - val_accuracy: 0.1983\n",
      "Epoch 376/1500\n",
      "126/126 [==============================] - 4s 32ms/step - loss: 0.1333 - accuracy: 0.8724 - val_loss: 0.9398 - val_accuracy: 0.1962\n",
      "Epoch 377/1500\n",
      "126/126 [==============================] - 4s 34ms/step - loss: 0.1332 - accuracy: 0.8790 - val_loss: 0.9380 - val_accuracy: 0.1941\n",
      "Epoch 378/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1327 - accuracy: 0.8767 - val_loss: 0.9386 - val_accuracy: 0.2025\n",
      "Epoch 379/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1330 - accuracy: 0.8854 - val_loss: 0.9392 - val_accuracy: 0.1941\n",
      "Epoch 380/1500\n",
      "126/126 [==============================] - 8s 62ms/step - loss: 0.1349 - accuracy: 0.8711 - val_loss: 0.9373 - val_accuracy: 0.1994\n",
      "Epoch 381/1500\n",
      "126/126 [==============================] - 4s 35ms/step - loss: 0.1327 - accuracy: 0.8838 - val_loss: 0.9397 - val_accuracy: 0.1983\n",
      "Epoch 382/1500\n",
      "126/126 [==============================] - 4s 33ms/step - loss: 0.1320 - accuracy: 0.8737 - val_loss: 0.9420 - val_accuracy: 0.1898\n",
      "Epoch 383/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1344 - accuracy: 0.8679 - val_loss: 0.9426 - val_accuracy: 0.2025\n",
      "Epoch 384/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1338 - accuracy: 0.8724 - val_loss: 0.9411 - val_accuracy: 0.1951\n",
      "Epoch 385/1500\n",
      "126/126 [==============================] - 4s 32ms/step - loss: 0.1317 - accuracy: 0.8785 - val_loss: 0.9425 - val_accuracy: 0.1866\n",
      "Epoch 386/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1312 - accuracy: 0.8716 - val_loss: 0.9390 - val_accuracy: 0.1994\n",
      "Epoch 387/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1301 - accuracy: 0.8769 - val_loss: 0.9412 - val_accuracy: 0.1909\n",
      "Epoch 388/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1317 - accuracy: 0.8745 - val_loss: 0.9402 - val_accuracy: 0.2089\n",
      "Epoch 389/1500\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 0.1321 - accuracy: 0.8785 - val_loss: 0.9416 - val_accuracy: 0.1972\n",
      "Epoch 390/1500\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 0.1307 - accuracy: 0.8743 - val_loss: 0.9409 - val_accuracy: 0.2004\n",
      "Epoch 391/1500\n",
      "126/126 [==============================] - 3s 28ms/step - loss: 0.1313 - accuracy: 0.8745 - val_loss: 0.9414 - val_accuracy: 0.2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/1500\n",
      "126/126 [==============================] - 4s 34ms/step - loss: 0.1313 - accuracy: 0.8729 - val_loss: 0.9402 - val_accuracy: 0.2068\n",
      "Epoch 393/1500\n",
      "126/126 [==============================] - 5s 38ms/step - loss: 0.1301 - accuracy: 0.8814 - val_loss: 0.9388 - val_accuracy: 0.2068\n",
      "Epoch 394/1500\n",
      "126/126 [==============================] - 4s 34ms/step - loss: 0.1314 - accuracy: 0.8785 - val_loss: 0.9382 - val_accuracy: 0.1994\n",
      "Epoch 395/1500\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 0.1322 - accuracy: 0.8769 - val_loss: 0.9377 - val_accuracy: 0.2057\n",
      "Epoch 396/1500\n",
      "126/126 [==============================] - 4s 32ms/step - loss: 0.1299 - accuracy: 0.8682 - val_loss: 0.9347 - val_accuracy: 0.1994\n",
      "Epoch 397/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1316 - accuracy: 0.8732 - val_loss: 0.9385 - val_accuracy: 0.1994\n",
      "Epoch 398/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1310 - accuracy: 0.8756 - val_loss: 0.9376 - val_accuracy: 0.1962\n",
      "Epoch 399/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1299 - accuracy: 0.8708 - val_loss: 0.9405 - val_accuracy: 0.2078\n",
      "Epoch 400/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1307 - accuracy: 0.8767 - val_loss: 0.9387 - val_accuracy: 0.2057\n",
      "Epoch 401/1500\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 0.1295 - accuracy: 0.8836 - val_loss: 0.9409 - val_accuracy: 0.2004\n",
      "Epoch 402/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1325 - accuracy: 0.8698 - val_loss: 0.9405 - val_accuracy: 0.1898\n",
      "Epoch 403/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1311 - accuracy: 0.8751 - val_loss: 0.9394 - val_accuracy: 0.1813\n",
      "Epoch 404/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1295 - accuracy: 0.8790 - val_loss: 0.9429 - val_accuracy: 0.1866\n",
      "Epoch 405/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1307 - accuracy: 0.8801 - val_loss: 0.9428 - val_accuracy: 0.1909\n",
      "Epoch 406/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1303 - accuracy: 0.8745 - val_loss: 0.9396 - val_accuracy: 0.1866\n",
      "Epoch 407/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1284 - accuracy: 0.8698 - val_loss: 0.9397 - val_accuracy: 0.1972\n",
      "Epoch 408/1500\n",
      "126/126 [==============================] - 5s 36ms/step - loss: 0.1299 - accuracy: 0.8798 - val_loss: 0.9398 - val_accuracy: 0.1845\n",
      "Epoch 409/1500\n",
      "126/126 [==============================] - 4s 33ms/step - loss: 0.1298 - accuracy: 0.8753 - val_loss: 0.9362 - val_accuracy: 0.1888\n",
      "Epoch 410/1500\n",
      "126/126 [==============================] - 4s 33ms/step - loss: 0.1303 - accuracy: 0.8814 - val_loss: 0.9394 - val_accuracy: 0.1994\n",
      "Epoch 411/1500\n",
      "126/126 [==============================] - 3s 28ms/step - loss: 0.1295 - accuracy: 0.8769 - val_loss: 0.9414 - val_accuracy: 0.1962\n",
      "Epoch 412/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1301 - accuracy: 0.8668 - val_loss: 0.9405 - val_accuracy: 0.1856\n",
      "Epoch 413/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1298 - accuracy: 0.8761 - val_loss: 0.9405 - val_accuracy: 0.1898\n",
      "Epoch 414/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1292 - accuracy: 0.8777 - val_loss: 0.9405 - val_accuracy: 0.2015\n",
      "Epoch 415/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1292 - accuracy: 0.8767 - val_loss: 0.9413 - val_accuracy: 0.1909\n",
      "Epoch 416/1500\n",
      "126/126 [==============================] - 4s 33ms/step - loss: 0.1303 - accuracy: 0.8711 - val_loss: 0.9406 - val_accuracy: 0.1983\n",
      "Epoch 417/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1301 - accuracy: 0.8732 - val_loss: 0.9393 - val_accuracy: 0.1845\n",
      "Epoch 418/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1289 - accuracy: 0.8780 - val_loss: 0.9387 - val_accuracy: 0.1951\n",
      "Epoch 419/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1310 - accuracy: 0.8782 - val_loss: 0.9386 - val_accuracy: 0.1951\n",
      "Epoch 420/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1298 - accuracy: 0.8804 - val_loss: 0.9354 - val_accuracy: 0.1919\n",
      "Epoch 421/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1291 - accuracy: 0.8801 - val_loss: 0.9355 - val_accuracy: 0.1866\n",
      "Epoch 422/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1295 - accuracy: 0.8700 - val_loss: 0.9384 - val_accuracy: 0.1983\n",
      "Epoch 423/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1296 - accuracy: 0.8825 - val_loss: 0.9366 - val_accuracy: 0.1919\n",
      "Epoch 424/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1298 - accuracy: 0.8767 - val_loss: 0.9373 - val_accuracy: 0.2047\n",
      "Epoch 425/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1301 - accuracy: 0.8743 - val_loss: 0.9385 - val_accuracy: 0.1994\n",
      "Epoch 426/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1288 - accuracy: 0.8753 - val_loss: 0.9368 - val_accuracy: 0.2068\n",
      "Epoch 427/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1290 - accuracy: 0.8788 - val_loss: 0.9383 - val_accuracy: 0.1930\n",
      "Epoch 428/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1276 - accuracy: 0.8849 - val_loss: 0.9378 - val_accuracy: 0.1888\n",
      "Epoch 429/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1276 - accuracy: 0.8735 - val_loss: 0.9387 - val_accuracy: 0.1919\n",
      "Epoch 430/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1287 - accuracy: 0.8793 - val_loss: 0.9389 - val_accuracy: 0.1888\n",
      "Epoch 431/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1291 - accuracy: 0.8748 - val_loss: 0.9397 - val_accuracy: 0.1972\n",
      "Epoch 432/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1278 - accuracy: 0.8782 - val_loss: 0.9433 - val_accuracy: 0.1888\n",
      "Epoch 433/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1277 - accuracy: 0.8790 - val_loss: 0.9407 - val_accuracy: 0.1983\n",
      "Epoch 434/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1269 - accuracy: 0.8753 - val_loss: 0.9387 - val_accuracy: 0.1898\n",
      "Epoch 435/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1263 - accuracy: 0.8830 - val_loss: 0.9379 - val_accuracy: 0.1962\n",
      "Epoch 436/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1274 - accuracy: 0.8716 - val_loss: 0.9357 - val_accuracy: 0.2004\n",
      "Epoch 437/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1274 - accuracy: 0.8822 - val_loss: 0.9383 - val_accuracy: 0.1941\n",
      "Epoch 438/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1280 - accuracy: 0.8732 - val_loss: 0.9375 - val_accuracy: 0.1930\n",
      "Epoch 439/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1278 - accuracy: 0.8801 - val_loss: 0.9388 - val_accuracy: 0.1930\n",
      "Epoch 440/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1275 - accuracy: 0.8772 - val_loss: 0.9397 - val_accuracy: 0.2047\n",
      "Epoch 441/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1291 - accuracy: 0.8844 - val_loss: 0.9390 - val_accuracy: 0.1994\n",
      "Epoch 442/1500\n",
      "126/126 [==============================] - 3s 28ms/step - loss: 0.1275 - accuracy: 0.8798 - val_loss: 0.9386 - val_accuracy: 0.1983\n",
      "Epoch 443/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1268 - accuracy: 0.8817 - val_loss: 0.9388 - val_accuracy: 0.2015\n",
      "Epoch 444/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1281 - accuracy: 0.8867 - val_loss: 0.9374 - val_accuracy: 0.2068\n",
      "Epoch 445/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1271 - accuracy: 0.8822 - val_loss: 0.9371 - val_accuracy: 0.1919\n",
      "Epoch 446/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1274 - accuracy: 0.8737 - val_loss: 0.9418 - val_accuracy: 0.1919\n",
      "Epoch 447/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1258 - accuracy: 0.8777 - val_loss: 0.9415 - val_accuracy: 0.1919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1269 - accuracy: 0.8780 - val_loss: 0.9400 - val_accuracy: 0.1930\n",
      "Epoch 449/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1269 - accuracy: 0.8910 - val_loss: 0.9434 - val_accuracy: 0.1877\n",
      "Epoch 450/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1272 - accuracy: 0.8851 - val_loss: 0.9406 - val_accuracy: 0.1972\n",
      "Epoch 451/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1264 - accuracy: 0.8844 - val_loss: 0.9403 - val_accuracy: 0.1941\n",
      "Epoch 452/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1253 - accuracy: 0.8814 - val_loss: 0.9374 - val_accuracy: 0.1919\n",
      "Epoch 453/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1278 - accuracy: 0.8692 - val_loss: 0.9398 - val_accuracy: 0.1994\n",
      "Epoch 454/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1256 - accuracy: 0.8846 - val_loss: 0.9395 - val_accuracy: 0.1972\n",
      "Epoch 455/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1270 - accuracy: 0.8833 - val_loss: 0.9399 - val_accuracy: 0.1909\n",
      "Epoch 456/1500\n",
      "126/126 [==============================] - 3s 28ms/step - loss: 0.1261 - accuracy: 0.8828 - val_loss: 0.9406 - val_accuracy: 0.1909\n",
      "Epoch 457/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1261 - accuracy: 0.8857 - val_loss: 0.9373 - val_accuracy: 0.2089\n",
      "Epoch 458/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1268 - accuracy: 0.8857 - val_loss: 0.9410 - val_accuracy: 0.2004\n",
      "Epoch 459/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1258 - accuracy: 0.8865 - val_loss: 0.9405 - val_accuracy: 0.1951\n",
      "Epoch 460/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1260 - accuracy: 0.8838 - val_loss: 0.9391 - val_accuracy: 0.1824\n",
      "Epoch 461/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1241 - accuracy: 0.8875 - val_loss: 0.9403 - val_accuracy: 0.1919\n",
      "Epoch 462/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1261 - accuracy: 0.8883 - val_loss: 0.9373 - val_accuracy: 0.1951\n",
      "Epoch 463/1500\n",
      "126/126 [==============================] - 3s 23ms/step - loss: 0.1274 - accuracy: 0.8825 - val_loss: 0.9420 - val_accuracy: 0.1962\n",
      "Epoch 464/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1260 - accuracy: 0.8806 - val_loss: 0.9402 - val_accuracy: 0.2015\n",
      "Epoch 465/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1256 - accuracy: 0.8796 - val_loss: 0.9392 - val_accuracy: 0.1994\n",
      "Epoch 466/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1259 - accuracy: 0.8881 - val_loss: 0.9393 - val_accuracy: 0.1919\n",
      "Epoch 467/1500\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 0.1247 - accuracy: 0.8862 - val_loss: 0.9383 - val_accuracy: 0.1994\n",
      "Epoch 468/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1262 - accuracy: 0.8862 - val_loss: 0.9422 - val_accuracy: 0.1909\n",
      "Epoch 469/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1255 - accuracy: 0.8748 - val_loss: 0.9371 - val_accuracy: 0.1909\n",
      "Epoch 470/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1250 - accuracy: 0.8873 - val_loss: 0.9364 - val_accuracy: 0.1941\n",
      "Epoch 471/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1248 - accuracy: 0.8854 - val_loss: 0.9359 - val_accuracy: 0.1972\n",
      "Epoch 472/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1262 - accuracy: 0.8814 - val_loss: 0.9381 - val_accuracy: 0.1941\n",
      "Epoch 473/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1251 - accuracy: 0.8788 - val_loss: 0.9376 - val_accuracy: 0.1930\n",
      "Epoch 474/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1254 - accuracy: 0.8844 - val_loss: 0.9368 - val_accuracy: 0.1888\n",
      "Epoch 475/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1238 - accuracy: 0.8788 - val_loss: 0.9370 - val_accuracy: 0.1909\n",
      "Epoch 476/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1256 - accuracy: 0.8809 - val_loss: 0.9398 - val_accuracy: 0.2015\n",
      "Epoch 477/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1257 - accuracy: 0.8891 - val_loss: 0.9414 - val_accuracy: 0.1930\n",
      "Epoch 478/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1252 - accuracy: 0.8798 - val_loss: 0.9358 - val_accuracy: 0.1941\n",
      "Epoch 479/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1250 - accuracy: 0.8859 - val_loss: 0.9351 - val_accuracy: 0.1930\n",
      "Epoch 480/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1233 - accuracy: 0.8844 - val_loss: 0.9343 - val_accuracy: 0.1951\n",
      "Epoch 481/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1251 - accuracy: 0.8870 - val_loss: 0.9388 - val_accuracy: 0.1951\n",
      "Epoch 482/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1255 - accuracy: 0.8767 - val_loss: 0.9395 - val_accuracy: 0.1919\n",
      "Epoch 483/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1242 - accuracy: 0.8737 - val_loss: 0.9387 - val_accuracy: 0.2025\n",
      "Epoch 484/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1247 - accuracy: 0.8809 - val_loss: 0.9397 - val_accuracy: 0.1888\n",
      "Epoch 485/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1237 - accuracy: 0.8804 - val_loss: 0.9375 - val_accuracy: 0.1983\n",
      "Epoch 486/1500\n",
      "126/126 [==============================] - 3s 23ms/step - loss: 0.1232 - accuracy: 0.8833 - val_loss: 0.9382 - val_accuracy: 0.2004\n",
      "Epoch 487/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1239 - accuracy: 0.8801 - val_loss: 0.9407 - val_accuracy: 0.1835\n",
      "Epoch 488/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1245 - accuracy: 0.8854 - val_loss: 0.9393 - val_accuracy: 0.1951\n",
      "Epoch 489/1500\n",
      "126/126 [==============================] - 3s 23ms/step - loss: 0.1246 - accuracy: 0.8828 - val_loss: 0.9370 - val_accuracy: 0.2047\n",
      "Epoch 490/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1246 - accuracy: 0.8838 - val_loss: 0.9363 - val_accuracy: 0.1951\n",
      "Epoch 491/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1245 - accuracy: 0.8902 - val_loss: 0.9379 - val_accuracy: 0.1994\n",
      "Epoch 492/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1234 - accuracy: 0.8849 - val_loss: 0.9386 - val_accuracy: 0.1888\n",
      "Epoch 493/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1232 - accuracy: 0.8825 - val_loss: 0.9378 - val_accuracy: 0.2004\n",
      "Epoch 494/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1225 - accuracy: 0.8881 - val_loss: 0.9388 - val_accuracy: 0.2100\n",
      "Epoch 495/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1232 - accuracy: 0.8785 - val_loss: 0.9389 - val_accuracy: 0.2057\n",
      "Epoch 496/1500\n",
      "126/126 [==============================] - 3s 23ms/step - loss: 0.1236 - accuracy: 0.8846 - val_loss: 0.9367 - val_accuracy: 0.1951\n",
      "Epoch 497/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1230 - accuracy: 0.8844 - val_loss: 0.9385 - val_accuracy: 0.2036\n",
      "Epoch 498/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1238 - accuracy: 0.8915 - val_loss: 0.9391 - val_accuracy: 0.2047\n",
      "Epoch 499/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1242 - accuracy: 0.8851 - val_loss: 0.9399 - val_accuracy: 0.1856\n",
      "Epoch 500/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1245 - accuracy: 0.8790 - val_loss: 0.9370 - val_accuracy: 0.1866\n",
      "Epoch 501/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1236 - accuracy: 0.8846 - val_loss: 0.9354 - val_accuracy: 0.1962\n",
      "Epoch 502/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1236 - accuracy: 0.8859 - val_loss: 0.9361 - val_accuracy: 0.1951\n",
      "Epoch 503/1500\n",
      "126/126 [==============================] - 3s 23ms/step - loss: 0.1228 - accuracy: 0.8851 - val_loss: 0.9392 - val_accuracy: 0.1919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1235 - accuracy: 0.8769 - val_loss: 0.9389 - val_accuracy: 0.1962\n",
      "Epoch 505/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1238 - accuracy: 0.8851 - val_loss: 0.9355 - val_accuracy: 0.2025\n",
      "Epoch 506/1500\n",
      "126/126 [==============================] - 3s 23ms/step - loss: 0.1229 - accuracy: 0.8809 - val_loss: 0.9371 - val_accuracy: 0.1919\n",
      "Epoch 507/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1217 - accuracy: 0.8899 - val_loss: 0.9376 - val_accuracy: 0.1888\n",
      "Epoch 508/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1237 - accuracy: 0.8897 - val_loss: 0.9393 - val_accuracy: 0.1930\n",
      "Epoch 509/1500\n",
      "126/126 [==============================] - 3s 28ms/step - loss: 0.1227 - accuracy: 0.8966 - val_loss: 0.9389 - val_accuracy: 0.1951\n",
      "Epoch 510/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1230 - accuracy: 0.8854 - val_loss: 0.9403 - val_accuracy: 0.1888\n",
      "Epoch 511/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1240 - accuracy: 0.8775 - val_loss: 0.9381 - val_accuracy: 0.1972\n",
      "Epoch 512/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1218 - accuracy: 0.8878 - val_loss: 0.9345 - val_accuracy: 0.1951\n",
      "Epoch 513/1500\n",
      "126/126 [==============================] - 3s 23ms/step - loss: 0.1221 - accuracy: 0.8828 - val_loss: 0.9391 - val_accuracy: 0.1951\n",
      "Epoch 514/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1231 - accuracy: 0.8915 - val_loss: 0.9376 - val_accuracy: 0.1866\n",
      "Epoch 515/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1229 - accuracy: 0.8793 - val_loss: 0.9359 - val_accuracy: 0.2015\n",
      "Epoch 516/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1230 - accuracy: 0.8883 - val_loss: 0.9371 - val_accuracy: 0.1930\n",
      "Epoch 517/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1223 - accuracy: 0.8865 - val_loss: 0.9364 - val_accuracy: 0.1930\n",
      "Epoch 518/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1228 - accuracy: 0.8833 - val_loss: 0.9408 - val_accuracy: 0.1898\n",
      "Epoch 519/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1214 - accuracy: 0.8897 - val_loss: 0.9418 - val_accuracy: 0.1845\n",
      "Epoch 520/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1225 - accuracy: 0.8836 - val_loss: 0.9355 - val_accuracy: 0.1930\n",
      "Epoch 521/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1231 - accuracy: 0.8846 - val_loss: 0.9355 - val_accuracy: 0.2004\n",
      "Epoch 522/1500\n",
      "126/126 [==============================] - 3s 28ms/step - loss: 0.1228 - accuracy: 0.8772 - val_loss: 0.9390 - val_accuracy: 0.1898\n",
      "Epoch 523/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1225 - accuracy: 0.8782 - val_loss: 0.9397 - val_accuracy: 0.1941\n",
      "Epoch 524/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1214 - accuracy: 0.8838 - val_loss: 0.9392 - val_accuracy: 0.2004\n",
      "Epoch 525/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1207 - accuracy: 0.8950 - val_loss: 0.9384 - val_accuracy: 0.1994\n",
      "Epoch 526/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1209 - accuracy: 0.8836 - val_loss: 0.9379 - val_accuracy: 0.2036\n",
      "Epoch 527/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1216 - accuracy: 0.8947 - val_loss: 0.9396 - val_accuracy: 0.2004\n",
      "Epoch 528/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1212 - accuracy: 0.8830 - val_loss: 0.9396 - val_accuracy: 0.1930\n",
      "Epoch 529/1500\n",
      "126/126 [==============================] - 4s 33ms/step - loss: 0.1219 - accuracy: 0.8883 - val_loss: 0.9386 - val_accuracy: 0.1941\n",
      "Epoch 530/1500\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 0.1215 - accuracy: 0.8950 - val_loss: 0.9391 - val_accuracy: 0.1972\n",
      "Epoch 531/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1217 - accuracy: 0.8886 - val_loss: 0.9395 - val_accuracy: 0.1919\n",
      "Epoch 532/1500\n",
      "126/126 [==============================] - 5s 41ms/step - loss: 0.1205 - accuracy: 0.8865 - val_loss: 0.9393 - val_accuracy: 0.1941\n",
      "Epoch 533/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1220 - accuracy: 0.8867 - val_loss: 0.9380 - val_accuracy: 0.2004\n",
      "Epoch 534/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1222 - accuracy: 0.8844 - val_loss: 0.9365 - val_accuracy: 0.2057\n",
      "Epoch 535/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1213 - accuracy: 0.8867 - val_loss: 0.9369 - val_accuracy: 0.2110\n",
      "Epoch 536/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1209 - accuracy: 0.8859 - val_loss: 0.9400 - val_accuracy: 0.2004\n",
      "Epoch 537/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1208 - accuracy: 0.8881 - val_loss: 0.9378 - val_accuracy: 0.1930\n",
      "Epoch 538/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1206 - accuracy: 0.8828 - val_loss: 0.9392 - val_accuracy: 0.1994\n",
      "Epoch 539/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1211 - accuracy: 0.8928 - val_loss: 0.9397 - val_accuracy: 0.1962\n",
      "Epoch 540/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1210 - accuracy: 0.8894 - val_loss: 0.9381 - val_accuracy: 0.1930\n",
      "Epoch 541/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1197 - accuracy: 0.8801 - val_loss: 0.9359 - val_accuracy: 0.1962\n",
      "Epoch 542/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1212 - accuracy: 0.8828 - val_loss: 0.9358 - val_accuracy: 0.1983\n",
      "Epoch 543/1500\n",
      "126/126 [==============================] - 4s 34ms/step - loss: 0.1210 - accuracy: 0.8875 - val_loss: 0.9393 - val_accuracy: 0.1835\n",
      "Epoch 544/1500\n",
      "126/126 [==============================] - 6s 45ms/step - loss: 0.1220 - accuracy: 0.8891 - val_loss: 0.9382 - val_accuracy: 0.1994\n",
      "Epoch 545/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1204 - accuracy: 0.8875 - val_loss: 0.9371 - val_accuracy: 0.1919\n",
      "Epoch 546/1500\n",
      "126/126 [==============================] - 3s 28ms/step - loss: 0.1205 - accuracy: 0.8814 - val_loss: 0.9340 - val_accuracy: 0.1909\n",
      "Epoch 547/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1205 - accuracy: 0.8838 - val_loss: 0.9346 - val_accuracy: 0.2036\n",
      "Epoch 548/1500\n",
      "126/126 [==============================] - 3s 28ms/step - loss: 0.1201 - accuracy: 0.8851 - val_loss: 0.9369 - val_accuracy: 0.1951\n",
      "Epoch 549/1500\n",
      "126/126 [==============================] - 4s 34ms/step - loss: 0.1217 - accuracy: 0.8881 - val_loss: 0.9366 - val_accuracy: 0.1972\n",
      "Epoch 550/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1212 - accuracy: 0.8923 - val_loss: 0.9369 - val_accuracy: 0.1983\n",
      "Epoch 551/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1194 - accuracy: 0.8851 - val_loss: 0.9344 - val_accuracy: 0.1962\n",
      "Epoch 552/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1213 - accuracy: 0.8796 - val_loss: 0.9389 - val_accuracy: 0.1888\n",
      "Epoch 553/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1199 - accuracy: 0.8825 - val_loss: 0.9385 - val_accuracy: 0.1941\n",
      "Epoch 554/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1209 - accuracy: 0.8798 - val_loss: 0.9363 - val_accuracy: 0.1941\n",
      "Epoch 555/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1222 - accuracy: 0.8809 - val_loss: 0.9356 - val_accuracy: 0.1919\n",
      "Epoch 556/1500\n",
      "126/126 [==============================] - 3s 28ms/step - loss: 0.1219 - accuracy: 0.8851 - val_loss: 0.9369 - val_accuracy: 0.1994\n",
      "Epoch 557/1500\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 0.1202 - accuracy: 0.8902 - val_loss: 0.9379 - val_accuracy: 0.1994\n",
      "Epoch 558/1500\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 0.1198 - accuracy: 0.8820 - val_loss: 0.9349 - val_accuracy: 0.1972\n",
      "Epoch 559/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1199 - accuracy: 0.8849 - val_loss: 0.9350 - val_accuracy: 0.2036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 560/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1194 - accuracy: 0.8910 - val_loss: 0.9371 - val_accuracy: 0.1972\n",
      "Epoch 561/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1200 - accuracy: 0.8915 - val_loss: 0.9387 - val_accuracy: 0.1972\n",
      "Epoch 562/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1212 - accuracy: 0.8878 - val_loss: 0.9368 - val_accuracy: 0.2015\n",
      "Epoch 563/1500\n",
      "126/126 [==============================] - 4s 35ms/step - loss: 0.1204 - accuracy: 0.8814 - val_loss: 0.9356 - val_accuracy: 0.1972\n",
      "Epoch 564/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1182 - accuracy: 0.8883 - val_loss: 0.9371 - val_accuracy: 0.2057\n",
      "Epoch 565/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1203 - accuracy: 0.8878 - val_loss: 0.9385 - val_accuracy: 0.1951\n",
      "Epoch 566/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1210 - accuracy: 0.8846 - val_loss: 0.9393 - val_accuracy: 0.1888\n",
      "Epoch 567/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1195 - accuracy: 0.8822 - val_loss: 0.9375 - val_accuracy: 0.1951\n",
      "Epoch 568/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1184 - accuracy: 0.8905 - val_loss: 0.9367 - val_accuracy: 0.2100\n",
      "Epoch 569/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1205 - accuracy: 0.8775 - val_loss: 0.9359 - val_accuracy: 0.1983\n",
      "Epoch 570/1500\n",
      "126/126 [==============================] - 5s 36ms/step - loss: 0.1193 - accuracy: 0.8886 - val_loss: 0.9351 - val_accuracy: 0.2036\n",
      "Epoch 571/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1196 - accuracy: 0.8793 - val_loss: 0.9395 - val_accuracy: 0.1962\n",
      "Epoch 572/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1198 - accuracy: 0.8944 - val_loss: 0.9398 - val_accuracy: 0.1909\n",
      "Epoch 573/1500\n",
      "126/126 [==============================] - 4s 33ms/step - loss: 0.1191 - accuracy: 0.8830 - val_loss: 0.9378 - val_accuracy: 0.1898\n",
      "Epoch 574/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1206 - accuracy: 0.8857 - val_loss: 0.9374 - val_accuracy: 0.1972\n",
      "Epoch 575/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1193 - accuracy: 0.8828 - val_loss: 0.9382 - val_accuracy: 0.1962\n",
      "Epoch 576/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1188 - accuracy: 0.8939 - val_loss: 0.9367 - val_accuracy: 0.1930\n",
      "Epoch 577/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1197 - accuracy: 0.8849 - val_loss: 0.9343 - val_accuracy: 0.1941\n",
      "Epoch 578/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1193 - accuracy: 0.8979 - val_loss: 0.9376 - val_accuracy: 0.1909\n",
      "Epoch 579/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1192 - accuracy: 0.8862 - val_loss: 0.9391 - val_accuracy: 0.1919\n",
      "Epoch 580/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1193 - accuracy: 0.8875 - val_loss: 0.9383 - val_accuracy: 0.2004\n",
      "Epoch 581/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1201 - accuracy: 0.8775 - val_loss: 0.9344 - val_accuracy: 0.1941\n",
      "Epoch 582/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1186 - accuracy: 0.8910 - val_loss: 0.9385 - val_accuracy: 0.1951\n",
      "Epoch 583/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1189 - accuracy: 0.8798 - val_loss: 0.9375 - val_accuracy: 0.1951\n",
      "Epoch 584/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1188 - accuracy: 0.8886 - val_loss: 0.9399 - val_accuracy: 0.2036\n",
      "Epoch 585/1500\n",
      "126/126 [==============================] - 4s 32ms/step - loss: 0.1192 - accuracy: 0.8942 - val_loss: 0.9362 - val_accuracy: 0.2025\n",
      "Epoch 586/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1194 - accuracy: 0.8897 - val_loss: 0.9378 - val_accuracy: 0.2025\n",
      "Epoch 587/1500\n",
      "126/126 [==============================] - 3s 23ms/step - loss: 0.1192 - accuracy: 0.8870 - val_loss: 0.9351 - val_accuracy: 0.2004\n",
      "Epoch 588/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1191 - accuracy: 0.8883 - val_loss: 0.9397 - val_accuracy: 0.1909\n",
      "Epoch 589/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1192 - accuracy: 0.8851 - val_loss: 0.9378 - val_accuracy: 0.1919\n",
      "Epoch 590/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1187 - accuracy: 0.8944 - val_loss: 0.9368 - val_accuracy: 0.2015\n",
      "Epoch 591/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1184 - accuracy: 0.8838 - val_loss: 0.9384 - val_accuracy: 0.1930\n",
      "Epoch 592/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1181 - accuracy: 0.8870 - val_loss: 0.9383 - val_accuracy: 0.1909\n",
      "Epoch 593/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1178 - accuracy: 0.8923 - val_loss: 0.9366 - val_accuracy: 0.1951\n",
      "Epoch 594/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1169 - accuracy: 0.8873 - val_loss: 0.9356 - val_accuracy: 0.1941\n",
      "Epoch 595/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1187 - accuracy: 0.8873 - val_loss: 0.9389 - val_accuracy: 0.1877\n",
      "Epoch 596/1500\n",
      "126/126 [==============================] - 3s 23ms/step - loss: 0.1189 - accuracy: 0.8881 - val_loss: 0.9373 - val_accuracy: 0.1951\n",
      "Epoch 597/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1172 - accuracy: 0.8841 - val_loss: 0.9382 - val_accuracy: 0.1994\n",
      "Epoch 598/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1190 - accuracy: 0.8950 - val_loss: 0.9399 - val_accuracy: 0.1919\n",
      "Epoch 599/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1189 - accuracy: 0.8923 - val_loss: 0.9387 - val_accuracy: 0.1898\n",
      "Epoch 600/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1180 - accuracy: 0.8846 - val_loss: 0.9369 - val_accuracy: 0.1856\n",
      "Epoch 601/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1188 - accuracy: 0.8878 - val_loss: 0.9364 - val_accuracy: 0.1888\n",
      "Epoch 602/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1173 - accuracy: 0.8955 - val_loss: 0.9380 - val_accuracy: 0.1919\n",
      "Epoch 603/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1182 - accuracy: 0.8912 - val_loss: 0.9392 - val_accuracy: 0.1962\n",
      "Epoch 604/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1188 - accuracy: 0.8830 - val_loss: 0.9331 - val_accuracy: 0.2047\n",
      "Epoch 605/1500\n",
      "126/126 [==============================] - 8s 60ms/step - loss: 0.1183 - accuracy: 0.8878 - val_loss: 0.9386 - val_accuracy: 0.2015\n",
      "Epoch 606/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1184 - accuracy: 0.8881 - val_loss: 0.9372 - val_accuracy: 0.1909\n",
      "Epoch 607/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1166 - accuracy: 0.8918 - val_loss: 0.9369 - val_accuracy: 0.2004\n",
      "Epoch 608/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1192 - accuracy: 0.8905 - val_loss: 0.9368 - val_accuracy: 0.1983\n",
      "Epoch 609/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1178 - accuracy: 0.8912 - val_loss: 0.9370 - val_accuracy: 0.2025\n",
      "Epoch 610/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1182 - accuracy: 0.8968 - val_loss: 0.9380 - val_accuracy: 0.1909\n",
      "Epoch 611/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1172 - accuracy: 0.8836 - val_loss: 0.9386 - val_accuracy: 0.1909\n",
      "Epoch 612/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1165 - accuracy: 0.8878 - val_loss: 0.9376 - val_accuracy: 0.1930\n",
      "Epoch 613/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1166 - accuracy: 0.8915 - val_loss: 0.9372 - val_accuracy: 0.1856\n",
      "Epoch 614/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1172 - accuracy: 0.8905 - val_loss: 0.9362 - val_accuracy: 0.1941\n",
      "Epoch 615/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1187 - accuracy: 0.8809 - val_loss: 0.9365 - val_accuracy: 0.1951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1174 - accuracy: 0.8881 - val_loss: 0.9380 - val_accuracy: 0.1898\n",
      "Epoch 617/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1180 - accuracy: 0.8944 - val_loss: 0.9401 - val_accuracy: 0.1877\n",
      "Epoch 618/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1190 - accuracy: 0.8870 - val_loss: 0.9373 - val_accuracy: 0.1972\n",
      "Epoch 619/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1179 - accuracy: 0.8851 - val_loss: 0.9381 - val_accuracy: 0.1983\n",
      "Epoch 620/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1179 - accuracy: 0.8886 - val_loss: 0.9353 - val_accuracy: 0.2025\n",
      "Epoch 621/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1181 - accuracy: 0.8918 - val_loss: 0.9384 - val_accuracy: 0.1972\n",
      "Epoch 622/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1156 - accuracy: 0.8958 - val_loss: 0.9351 - val_accuracy: 0.1994\n",
      "Epoch 623/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1183 - accuracy: 0.8849 - val_loss: 0.9371 - val_accuracy: 0.1909\n",
      "Epoch 624/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1183 - accuracy: 0.8859 - val_loss: 0.9366 - val_accuracy: 0.2015\n",
      "Epoch 625/1500\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 0.1163 - accuracy: 0.8973 - val_loss: 0.9374 - val_accuracy: 0.2036\n",
      "Epoch 626/1500\n",
      "126/126 [==============================] - 4s 34ms/step - loss: 0.1177 - accuracy: 0.8878 - val_loss: 0.9383 - val_accuracy: 0.2025\n",
      "Epoch 627/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1161 - accuracy: 0.8883 - val_loss: 0.9368 - val_accuracy: 0.2004\n",
      "Epoch 628/1500\n",
      "126/126 [==============================] - 4s 33ms/step - loss: 0.1171 - accuracy: 0.8891 - val_loss: 0.9380 - val_accuracy: 0.2004\n",
      "Epoch 629/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1158 - accuracy: 0.8955 - val_loss: 0.9358 - val_accuracy: 0.1909\n",
      "Epoch 630/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1183 - accuracy: 0.8801 - val_loss: 0.9349 - val_accuracy: 0.2047\n",
      "Epoch 631/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1163 - accuracy: 0.8942 - val_loss: 0.9374 - val_accuracy: 0.1972\n",
      "Epoch 632/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1166 - accuracy: 0.8867 - val_loss: 0.9346 - val_accuracy: 0.1962\n",
      "Epoch 633/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1168 - accuracy: 0.8870 - val_loss: 0.9336 - val_accuracy: 0.1962\n",
      "Epoch 634/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1158 - accuracy: 0.8836 - val_loss: 0.9351 - val_accuracy: 0.2015\n",
      "Epoch 635/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1156 - accuracy: 0.8981 - val_loss: 0.9360 - val_accuracy: 0.2078\n",
      "Epoch 636/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1162 - accuracy: 0.8907 - val_loss: 0.9363 - val_accuracy: 0.2004\n",
      "Epoch 637/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1161 - accuracy: 0.8939 - val_loss: 0.9366 - val_accuracy: 0.2025\n",
      "Epoch 638/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1163 - accuracy: 0.8865 - val_loss: 0.9340 - val_accuracy: 0.1898\n",
      "Epoch 639/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1172 - accuracy: 0.8918 - val_loss: 0.9390 - val_accuracy: 0.1919\n",
      "Epoch 640/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1173 - accuracy: 0.8889 - val_loss: 0.9359 - val_accuracy: 0.2057\n",
      "Epoch 641/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1151 - accuracy: 0.8944 - val_loss: 0.9384 - val_accuracy: 0.2015\n",
      "Epoch 642/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1158 - accuracy: 0.8918 - val_loss: 0.9389 - val_accuracy: 0.1972\n",
      "Epoch 643/1500\n",
      "126/126 [==============================] - 4s 32ms/step - loss: 0.1170 - accuracy: 0.8918 - val_loss: 0.9342 - val_accuracy: 0.2015\n",
      "Epoch 644/1500\n",
      "126/126 [==============================] - 4s 33ms/step - loss: 0.1153 - accuracy: 0.8881 - val_loss: 0.9391 - val_accuracy: 0.1888\n",
      "Epoch 645/1500\n",
      "126/126 [==============================] - 4s 35ms/step - loss: 0.1160 - accuracy: 0.8942 - val_loss: 0.9369 - val_accuracy: 0.1941\n",
      "Epoch 646/1500\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 0.1180 - accuracy: 0.8865 - val_loss: 0.9359 - val_accuracy: 0.1930\n",
      "Epoch 647/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1158 - accuracy: 0.8950 - val_loss: 0.9378 - val_accuracy: 0.1877\n",
      "Epoch 648/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1161 - accuracy: 0.8944 - val_loss: 0.9390 - val_accuracy: 0.1941\n",
      "Epoch 649/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1156 - accuracy: 0.8955 - val_loss: 0.9347 - val_accuracy: 0.1972\n",
      "Epoch 650/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1143 - accuracy: 0.8915 - val_loss: 0.9334 - val_accuracy: 0.2057\n",
      "Epoch 651/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1155 - accuracy: 0.8984 - val_loss: 0.9353 - val_accuracy: 0.2004\n",
      "Epoch 652/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1174 - accuracy: 0.8830 - val_loss: 0.9376 - val_accuracy: 0.1972\n",
      "Epoch 653/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1161 - accuracy: 0.8878 - val_loss: 0.9368 - val_accuracy: 0.1983\n",
      "Epoch 654/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1169 - accuracy: 0.8881 - val_loss: 0.9378 - val_accuracy: 0.1930\n",
      "Epoch 655/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1165 - accuracy: 0.8939 - val_loss: 0.9378 - val_accuracy: 0.1930\n",
      "Epoch 656/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1165 - accuracy: 0.8907 - val_loss: 0.9392 - val_accuracy: 0.1972\n",
      "Epoch 657/1500\n",
      "126/126 [==============================] - 8s 61ms/step - loss: 0.1145 - accuracy: 0.8878 - val_loss: 0.9364 - val_accuracy: 0.2089\n",
      "Epoch 658/1500\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 0.1162 - accuracy: 0.8905 - val_loss: 0.9370 - val_accuracy: 0.1941\n",
      "Epoch 659/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1150 - accuracy: 0.8952 - val_loss: 0.9372 - val_accuracy: 0.1951\n",
      "Epoch 660/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1165 - accuracy: 0.8865 - val_loss: 0.9316 - val_accuracy: 0.1877\n",
      "Epoch 661/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1168 - accuracy: 0.8910 - val_loss: 0.9375 - val_accuracy: 0.1888\n",
      "Epoch 662/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1149 - accuracy: 0.8947 - val_loss: 0.9348 - val_accuracy: 0.1951\n",
      "Epoch 663/1500\n",
      "126/126 [==============================] - 4s 32ms/step - loss: 0.1169 - accuracy: 0.8838 - val_loss: 0.9358 - val_accuracy: 0.1898\n",
      "Epoch 664/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1161 - accuracy: 0.8854 - val_loss: 0.9352 - val_accuracy: 0.1941\n",
      "Epoch 665/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1151 - accuracy: 0.8854 - val_loss: 0.9352 - val_accuracy: 0.1962\n",
      "Epoch 666/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1163 - accuracy: 0.8955 - val_loss: 0.9353 - val_accuracy: 0.1919\n",
      "Epoch 667/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1160 - accuracy: 0.8984 - val_loss: 0.9321 - val_accuracy: 0.1877\n",
      "Epoch 668/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1148 - accuracy: 0.8878 - val_loss: 0.9325 - val_accuracy: 0.1972\n",
      "Epoch 669/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1141 - accuracy: 0.8968 - val_loss: 0.9377 - val_accuracy: 0.2015\n",
      "Epoch 670/1500\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 0.1148 - accuracy: 0.8878 - val_loss: 0.9355 - val_accuracy: 0.2089\n",
      "Epoch 671/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1156 - accuracy: 0.8942 - val_loss: 0.9378 - val_accuracy: 0.2025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 672/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1151 - accuracy: 0.8971 - val_loss: 0.9366 - val_accuracy: 0.1962\n",
      "Epoch 673/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1157 - accuracy: 0.8936 - val_loss: 0.9369 - val_accuracy: 0.1888\n",
      "Epoch 674/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1147 - accuracy: 0.8963 - val_loss: 0.9331 - val_accuracy: 0.1962\n",
      "Epoch 675/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1141 - accuracy: 0.8897 - val_loss: 0.9356 - val_accuracy: 0.1983\n",
      "Epoch 676/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1136 - accuracy: 0.8841 - val_loss: 0.9341 - val_accuracy: 0.1919\n",
      "Epoch 677/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1153 - accuracy: 0.8875 - val_loss: 0.9350 - val_accuracy: 0.1930\n",
      "Epoch 678/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1147 - accuracy: 0.8944 - val_loss: 0.9339 - val_accuracy: 0.1941\n",
      "Epoch 679/1500\n",
      "126/126 [==============================] - 3s 28ms/step - loss: 0.1151 - accuracy: 0.8822 - val_loss: 0.9349 - val_accuracy: 0.1909\n",
      "Epoch 680/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1147 - accuracy: 0.8873 - val_loss: 0.9364 - val_accuracy: 0.2047\n",
      "Epoch 681/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1163 - accuracy: 0.8931 - val_loss: 0.9384 - val_accuracy: 0.2068\n",
      "Epoch 682/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1144 - accuracy: 0.8886 - val_loss: 0.9373 - val_accuracy: 0.1994\n",
      "Epoch 683/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1137 - accuracy: 0.8984 - val_loss: 0.9381 - val_accuracy: 0.2047\n",
      "Epoch 684/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1141 - accuracy: 0.8857 - val_loss: 0.9341 - val_accuracy: 0.2004\n",
      "Epoch 685/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1161 - accuracy: 0.8907 - val_loss: 0.9366 - val_accuracy: 0.2047\n",
      "Epoch 686/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1143 - accuracy: 0.8923 - val_loss: 0.9378 - val_accuracy: 0.1983\n",
      "Epoch 687/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1137 - accuracy: 0.8883 - val_loss: 0.9339 - val_accuracy: 0.2057\n",
      "Epoch 688/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1153 - accuracy: 0.8936 - val_loss: 0.9411 - val_accuracy: 0.1919\n",
      "Epoch 689/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1142 - accuracy: 0.8907 - val_loss: 0.9416 - val_accuracy: 0.1962\n",
      "Epoch 690/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1140 - accuracy: 0.8875 - val_loss: 0.9382 - val_accuracy: 0.1972\n",
      "Epoch 691/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1144 - accuracy: 0.8928 - val_loss: 0.9347 - val_accuracy: 0.1898\n",
      "Epoch 692/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1149 - accuracy: 0.8902 - val_loss: 0.9357 - val_accuracy: 0.2025\n",
      "Epoch 693/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1142 - accuracy: 0.8894 - val_loss: 0.9410 - val_accuracy: 0.2078\n",
      "Epoch 694/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1134 - accuracy: 0.8942 - val_loss: 0.9382 - val_accuracy: 0.1994\n",
      "Epoch 695/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1141 - accuracy: 0.8910 - val_loss: 0.9423 - val_accuracy: 0.1919\n",
      "Epoch 696/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1135 - accuracy: 0.8915 - val_loss: 0.9388 - val_accuracy: 0.1919\n",
      "Epoch 697/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1138 - accuracy: 0.8849 - val_loss: 0.9377 - val_accuracy: 0.2025\n",
      "Epoch 698/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1152 - accuracy: 0.8979 - val_loss: 0.9355 - val_accuracy: 0.1930\n",
      "Epoch 699/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1151 - accuracy: 0.8854 - val_loss: 0.9331 - val_accuracy: 0.1909\n",
      "Epoch 700/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1139 - accuracy: 0.9013 - val_loss: 0.9342 - val_accuracy: 0.1803\n",
      "Epoch 701/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1141 - accuracy: 0.8984 - val_loss: 0.9330 - val_accuracy: 0.1972\n",
      "Epoch 702/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1134 - accuracy: 0.8955 - val_loss: 0.9351 - val_accuracy: 0.1962\n",
      "Epoch 703/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1139 - accuracy: 0.8931 - val_loss: 0.9330 - val_accuracy: 0.1941\n",
      "Epoch 704/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1143 - accuracy: 0.8889 - val_loss: 0.9327 - val_accuracy: 0.1972\n",
      "Epoch 705/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1148 - accuracy: 0.8979 - val_loss: 0.9354 - val_accuracy: 0.1866\n",
      "Epoch 706/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1142 - accuracy: 0.8907 - val_loss: 0.9369 - val_accuracy: 0.1930\n",
      "Epoch 707/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1141 - accuracy: 0.8971 - val_loss: 0.9368 - val_accuracy: 0.1845\n",
      "Epoch 708/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1133 - accuracy: 0.8979 - val_loss: 0.9371 - val_accuracy: 0.1835\n",
      "Epoch 709/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1139 - accuracy: 0.8915 - val_loss: 0.9353 - val_accuracy: 0.1930\n",
      "Epoch 710/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1136 - accuracy: 0.8984 - val_loss: 0.9344 - val_accuracy: 0.1930\n",
      "Epoch 711/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1128 - accuracy: 0.9000 - val_loss: 0.9378 - val_accuracy: 0.1824\n",
      "Epoch 712/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1129 - accuracy: 0.8981 - val_loss: 0.9363 - val_accuracy: 0.1898\n",
      "Epoch 713/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1145 - accuracy: 0.8984 - val_loss: 0.9381 - val_accuracy: 0.1930\n",
      "Epoch 714/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1136 - accuracy: 0.8973 - val_loss: 0.9360 - val_accuracy: 0.1951\n",
      "Epoch 715/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1133 - accuracy: 0.8891 - val_loss: 0.9375 - val_accuracy: 0.1962\n",
      "Epoch 716/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1130 - accuracy: 0.8947 - val_loss: 0.9382 - val_accuracy: 0.1909\n",
      "Epoch 717/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1135 - accuracy: 0.8928 - val_loss: 0.9354 - val_accuracy: 0.1919\n",
      "Epoch 718/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1120 - accuracy: 0.8968 - val_loss: 0.9364 - val_accuracy: 0.1888\n",
      "Epoch 719/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1134 - accuracy: 0.8989 - val_loss: 0.9340 - val_accuracy: 0.1962\n",
      "Epoch 720/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1131 - accuracy: 0.8960 - val_loss: 0.9373 - val_accuracy: 0.1898\n",
      "Epoch 721/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1128 - accuracy: 0.8944 - val_loss: 0.9348 - val_accuracy: 0.1919\n",
      "Epoch 722/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1132 - accuracy: 0.8976 - val_loss: 0.9348 - val_accuracy: 0.1983\n",
      "Epoch 723/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1129 - accuracy: 0.8851 - val_loss: 0.9329 - val_accuracy: 0.2004\n",
      "Epoch 724/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1137 - accuracy: 0.8950 - val_loss: 0.9373 - val_accuracy: 0.1919\n",
      "Epoch 725/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1132 - accuracy: 0.8968 - val_loss: 0.9383 - val_accuracy: 0.1951\n",
      "Epoch 726/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1127 - accuracy: 0.8883 - val_loss: 0.9385 - val_accuracy: 0.1856\n",
      "Epoch 727/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1133 - accuracy: 0.8960 - val_loss: 0.9357 - val_accuracy: 0.2015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 728/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1131 - accuracy: 0.8950 - val_loss: 0.9358 - val_accuracy: 0.1962\n",
      "Epoch 729/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1128 - accuracy: 0.9021 - val_loss: 0.9391 - val_accuracy: 0.1930\n",
      "Epoch 730/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1125 - accuracy: 0.8905 - val_loss: 0.9395 - val_accuracy: 0.1909\n",
      "Epoch 731/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1132 - accuracy: 0.8984 - val_loss: 0.9390 - val_accuracy: 0.1813\n",
      "Epoch 732/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1124 - accuracy: 0.8971 - val_loss: 0.9371 - val_accuracy: 0.1909\n",
      "Epoch 733/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1135 - accuracy: 0.8963 - val_loss: 0.9380 - val_accuracy: 0.1856\n",
      "Epoch 734/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1136 - accuracy: 0.8920 - val_loss: 0.9362 - val_accuracy: 0.1983\n",
      "Epoch 735/1500\n",
      "126/126 [==============================] - 3s 23ms/step - loss: 0.1135 - accuracy: 0.8931 - val_loss: 0.9361 - val_accuracy: 0.1888\n",
      "Epoch 736/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1131 - accuracy: 0.8894 - val_loss: 0.9355 - val_accuracy: 0.1919\n",
      "Epoch 737/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1130 - accuracy: 0.8968 - val_loss: 0.9360 - val_accuracy: 0.1994\n",
      "Epoch 738/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1128 - accuracy: 0.8844 - val_loss: 0.9362 - val_accuracy: 0.1909\n",
      "Epoch 739/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1123 - accuracy: 0.8947 - val_loss: 0.9339 - val_accuracy: 0.1930\n",
      "Epoch 740/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1111 - accuracy: 0.8968 - val_loss: 0.9331 - val_accuracy: 0.1919\n",
      "Epoch 741/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1114 - accuracy: 0.9008 - val_loss: 0.9332 - val_accuracy: 0.1994\n",
      "Epoch 742/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1122 - accuracy: 0.8989 - val_loss: 0.9363 - val_accuracy: 0.1951\n",
      "Epoch 743/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1117 - accuracy: 0.8987 - val_loss: 0.9357 - val_accuracy: 0.1877\n",
      "Epoch 744/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1119 - accuracy: 0.8934 - val_loss: 0.9359 - val_accuracy: 0.1835\n",
      "Epoch 745/1500\n",
      "126/126 [==============================] - 3s 28ms/step - loss: 0.1128 - accuracy: 0.8976 - val_loss: 0.9356 - val_accuracy: 0.2025\n",
      "Epoch 746/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1118 - accuracy: 0.8934 - val_loss: 0.9350 - val_accuracy: 0.1994\n",
      "Epoch 747/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1146 - accuracy: 0.8912 - val_loss: 0.9381 - val_accuracy: 0.1962\n",
      "Epoch 748/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1119 - accuracy: 0.8979 - val_loss: 0.9398 - val_accuracy: 0.1898\n",
      "Epoch 749/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1111 - accuracy: 0.8997 - val_loss: 0.9344 - val_accuracy: 0.2047\n",
      "Epoch 750/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1127 - accuracy: 0.9008 - val_loss: 0.9374 - val_accuracy: 0.1930\n",
      "Epoch 751/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1122 - accuracy: 0.9037 - val_loss: 0.9354 - val_accuracy: 0.1983\n",
      "Epoch 752/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1114 - accuracy: 0.8997 - val_loss: 0.9366 - val_accuracy: 0.1888\n",
      "Epoch 753/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1130 - accuracy: 0.8897 - val_loss: 0.9349 - val_accuracy: 0.1888\n",
      "Epoch 754/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1120 - accuracy: 0.8902 - val_loss: 0.9355 - val_accuracy: 0.1962\n",
      "Epoch 755/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1128 - accuracy: 0.8910 - val_loss: 0.9351 - val_accuracy: 0.2004\n",
      "Epoch 756/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1133 - accuracy: 0.8886 - val_loss: 0.9386 - val_accuracy: 0.1909\n",
      "Epoch 757/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1114 - accuracy: 0.8931 - val_loss: 0.9367 - val_accuracy: 0.1930\n",
      "Epoch 758/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1113 - accuracy: 0.8989 - val_loss: 0.9389 - val_accuracy: 0.1994\n",
      "Epoch 759/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1109 - accuracy: 0.8950 - val_loss: 0.9407 - val_accuracy: 0.1898\n",
      "Epoch 760/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1131 - accuracy: 0.8934 - val_loss: 0.9409 - val_accuracy: 0.2078\n",
      "Epoch 761/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1122 - accuracy: 0.8918 - val_loss: 0.9412 - val_accuracy: 0.1962\n",
      "Epoch 762/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1109 - accuracy: 0.9034 - val_loss: 0.9422 - val_accuracy: 0.1909\n",
      "Epoch 763/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1119 - accuracy: 0.8889 - val_loss: 0.9427 - val_accuracy: 0.1941\n",
      "Epoch 764/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1118 - accuracy: 0.8944 - val_loss: 0.9379 - val_accuracy: 0.1951\n",
      "Epoch 765/1500\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 0.1131 - accuracy: 0.8902 - val_loss: 0.9371 - val_accuracy: 0.2057\n",
      "Epoch 766/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1119 - accuracy: 0.9053 - val_loss: 0.9381 - val_accuracy: 0.2004\n",
      "Epoch 767/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1111 - accuracy: 0.8950 - val_loss: 0.9376 - val_accuracy: 0.1994\n",
      "Epoch 768/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1107 - accuracy: 0.8920 - val_loss: 0.9394 - val_accuracy: 0.1877\n",
      "Epoch 769/1500\n",
      "126/126 [==============================] - 3s 23ms/step - loss: 0.1117 - accuracy: 0.8854 - val_loss: 0.9366 - val_accuracy: 0.1835\n",
      "Epoch 770/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1114 - accuracy: 0.8944 - val_loss: 0.9377 - val_accuracy: 0.1962\n",
      "Epoch 771/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1117 - accuracy: 0.8979 - val_loss: 0.9369 - val_accuracy: 0.2036\n",
      "Epoch 772/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1116 - accuracy: 0.8881 - val_loss: 0.9377 - val_accuracy: 0.1951\n",
      "Epoch 773/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1112 - accuracy: 0.8997 - val_loss: 0.9379 - val_accuracy: 0.1877\n",
      "Epoch 774/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1105 - accuracy: 0.9029 - val_loss: 0.9362 - val_accuracy: 0.1972\n",
      "Epoch 775/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1125 - accuracy: 0.8910 - val_loss: 0.9404 - val_accuracy: 0.1835\n",
      "Epoch 776/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1128 - accuracy: 0.8902 - val_loss: 0.9397 - val_accuracy: 0.1909\n",
      "Epoch 777/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1122 - accuracy: 0.8997 - val_loss: 0.9375 - val_accuracy: 0.1919\n",
      "Epoch 778/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1115 - accuracy: 0.8958 - val_loss: 0.9398 - val_accuracy: 0.1919\n",
      "Epoch 779/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1111 - accuracy: 0.9040 - val_loss: 0.9360 - val_accuracy: 0.1972\n",
      "Epoch 780/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1113 - accuracy: 0.8912 - val_loss: 0.9391 - val_accuracy: 0.1877\n",
      "Epoch 781/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1120 - accuracy: 0.8886 - val_loss: 0.9397 - val_accuracy: 0.1972\n",
      "Epoch 782/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1124 - accuracy: 0.8920 - val_loss: 0.9402 - val_accuracy: 0.1909\n",
      "Epoch 783/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1119 - accuracy: 0.8950 - val_loss: 0.9358 - val_accuracy: 0.1941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 784/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1116 - accuracy: 0.8968 - val_loss: 0.9397 - val_accuracy: 0.1877\n",
      "Epoch 785/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1110 - accuracy: 0.8928 - val_loss: 0.9374 - val_accuracy: 0.1941\n",
      "Epoch 786/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1124 - accuracy: 0.9058 - val_loss: 0.9397 - val_accuracy: 0.2036\n",
      "Epoch 787/1500\n",
      "126/126 [==============================] - 3s 23ms/step - loss: 0.1108 - accuracy: 0.9024 - val_loss: 0.9377 - val_accuracy: 0.2025\n",
      "Epoch 788/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1118 - accuracy: 0.8931 - val_loss: 0.9346 - val_accuracy: 0.1951\n",
      "Epoch 789/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1118 - accuracy: 0.8918 - val_loss: 0.9365 - val_accuracy: 0.1983\n",
      "Epoch 790/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1108 - accuracy: 0.9024 - val_loss: 0.9369 - val_accuracy: 0.1972\n",
      "Epoch 791/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1108 - accuracy: 0.9034 - val_loss: 0.9363 - val_accuracy: 0.1877\n",
      "Epoch 792/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1108 - accuracy: 0.8883 - val_loss: 0.9348 - val_accuracy: 0.1941\n",
      "Epoch 793/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1119 - accuracy: 0.8947 - val_loss: 0.9339 - val_accuracy: 0.1951\n",
      "Epoch 794/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1106 - accuracy: 0.8947 - val_loss: 0.9370 - val_accuracy: 0.1994\n",
      "Epoch 795/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1101 - accuracy: 0.9061 - val_loss: 0.9355 - val_accuracy: 0.2036\n",
      "Epoch 796/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1099 - accuracy: 0.8966 - val_loss: 0.9394 - val_accuracy: 0.1941\n",
      "Epoch 797/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1103 - accuracy: 0.8928 - val_loss: 0.9389 - val_accuracy: 0.1972\n",
      "Epoch 798/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1101 - accuracy: 0.8958 - val_loss: 0.9386 - val_accuracy: 0.1824\n",
      "Epoch 799/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1096 - accuracy: 0.8997 - val_loss: 0.9377 - val_accuracy: 0.1909\n",
      "Epoch 800/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1107 - accuracy: 0.8942 - val_loss: 0.9388 - val_accuracy: 0.1941\n",
      "Epoch 801/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1109 - accuracy: 0.8981 - val_loss: 0.9370 - val_accuracy: 0.2015\n",
      "Epoch 802/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1116 - accuracy: 0.9011 - val_loss: 0.9351 - val_accuracy: 0.1824\n",
      "Epoch 803/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1099 - accuracy: 0.8955 - val_loss: 0.9398 - val_accuracy: 0.2036\n",
      "Epoch 804/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1098 - accuracy: 0.8944 - val_loss: 0.9378 - val_accuracy: 0.1983\n",
      "Epoch 805/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1107 - accuracy: 0.8939 - val_loss: 0.9377 - val_accuracy: 0.1962\n",
      "Epoch 806/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1099 - accuracy: 0.8955 - val_loss: 0.9365 - val_accuracy: 0.1888\n",
      "Epoch 807/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1097 - accuracy: 0.9066 - val_loss: 0.9380 - val_accuracy: 0.1919\n",
      "Epoch 808/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1111 - accuracy: 0.8979 - val_loss: 0.9335 - val_accuracy: 0.2100\n",
      "Epoch 809/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1120 - accuracy: 0.8907 - val_loss: 0.9371 - val_accuracy: 0.2057\n",
      "Epoch 810/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1112 - accuracy: 0.8881 - val_loss: 0.9366 - val_accuracy: 0.1983\n",
      "Epoch 811/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1103 - accuracy: 0.8979 - val_loss: 0.9387 - val_accuracy: 0.1835\n",
      "Epoch 812/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1092 - accuracy: 0.8915 - val_loss: 0.9386 - val_accuracy: 0.1972\n",
      "Epoch 813/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1101 - accuracy: 0.8987 - val_loss: 0.9361 - val_accuracy: 0.1898\n",
      "Epoch 814/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1106 - accuracy: 0.8926 - val_loss: 0.9354 - val_accuracy: 0.1972\n",
      "Epoch 815/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1109 - accuracy: 0.8981 - val_loss: 0.9348 - val_accuracy: 0.1994\n",
      "Epoch 816/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1112 - accuracy: 0.8889 - val_loss: 0.9365 - val_accuracy: 0.2057\n",
      "Epoch 817/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1116 - accuracy: 0.8907 - val_loss: 0.9392 - val_accuracy: 0.1866\n",
      "Epoch 818/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1103 - accuracy: 0.8960 - val_loss: 0.9370 - val_accuracy: 0.1983\n",
      "Epoch 819/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1108 - accuracy: 0.8997 - val_loss: 0.9377 - val_accuracy: 0.1951\n",
      "Epoch 820/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1104 - accuracy: 0.8947 - val_loss: 0.9348 - val_accuracy: 0.1930\n",
      "Epoch 821/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1114 - accuracy: 0.8910 - val_loss: 0.9342 - val_accuracy: 0.1951\n",
      "Epoch 822/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1097 - accuracy: 0.8952 - val_loss: 0.9361 - val_accuracy: 0.2015\n",
      "Epoch 823/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1101 - accuracy: 0.9011 - val_loss: 0.9365 - val_accuracy: 0.2047\n",
      "Epoch 824/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1108 - accuracy: 0.8915 - val_loss: 0.9365 - val_accuracy: 0.1909\n",
      "Epoch 825/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1101 - accuracy: 0.8979 - val_loss: 0.9358 - val_accuracy: 0.1930\n",
      "Epoch 826/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1099 - accuracy: 0.8968 - val_loss: 0.9365 - val_accuracy: 0.1909\n",
      "Epoch 827/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1089 - accuracy: 0.8987 - val_loss: 0.9365 - val_accuracy: 0.1919\n",
      "Epoch 828/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1106 - accuracy: 0.9021 - val_loss: 0.9364 - val_accuracy: 0.1951\n",
      "Epoch 829/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1100 - accuracy: 0.8889 - val_loss: 0.9369 - val_accuracy: 0.1972\n",
      "Epoch 830/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1091 - accuracy: 0.8918 - val_loss: 0.9341 - val_accuracy: 0.1866\n",
      "Epoch 831/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1094 - accuracy: 0.8928 - val_loss: 0.9404 - val_accuracy: 0.2025\n",
      "Epoch 832/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1100 - accuracy: 0.8923 - val_loss: 0.9358 - val_accuracy: 0.1972\n",
      "Epoch 833/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1096 - accuracy: 0.8997 - val_loss: 0.9387 - val_accuracy: 0.1994\n",
      "Epoch 834/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1095 - accuracy: 0.8984 - val_loss: 0.9358 - val_accuracy: 0.1951\n",
      "Epoch 835/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1097 - accuracy: 0.8923 - val_loss: 0.9350 - val_accuracy: 0.2047\n",
      "Epoch 836/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1085 - accuracy: 0.9000 - val_loss: 0.9362 - val_accuracy: 0.1994\n",
      "Epoch 837/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1093 - accuracy: 0.8952 - val_loss: 0.9384 - val_accuracy: 0.2025\n",
      "Epoch 838/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1115 - accuracy: 0.8899 - val_loss: 0.9364 - val_accuracy: 0.1909\n",
      "Epoch 839/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1112 - accuracy: 0.8915 - val_loss: 0.9359 - val_accuracy: 0.2110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 840/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1091 - accuracy: 0.9005 - val_loss: 0.9330 - val_accuracy: 0.2004\n",
      "Epoch 841/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1095 - accuracy: 0.9048 - val_loss: 0.9359 - val_accuracy: 0.2131\n",
      "Epoch 842/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1102 - accuracy: 0.9032 - val_loss: 0.9354 - val_accuracy: 0.1951\n",
      "Epoch 843/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1097 - accuracy: 0.8846 - val_loss: 0.9348 - val_accuracy: 0.2004\n",
      "Epoch 844/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1097 - accuracy: 0.8905 - val_loss: 0.9348 - val_accuracy: 0.2004\n",
      "Epoch 845/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1083 - accuracy: 0.8963 - val_loss: 0.9347 - val_accuracy: 0.2015\n",
      "Epoch 846/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1092 - accuracy: 0.8905 - val_loss: 0.9370 - val_accuracy: 0.1930\n",
      "Epoch 847/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1085 - accuracy: 0.8981 - val_loss: 0.9358 - val_accuracy: 0.2036\n",
      "Epoch 848/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1092 - accuracy: 0.8944 - val_loss: 0.9354 - val_accuracy: 0.1919\n",
      "Epoch 849/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1082 - accuracy: 0.9013 - val_loss: 0.9398 - val_accuracy: 0.2025\n",
      "Epoch 850/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1101 - accuracy: 0.8952 - val_loss: 0.9369 - val_accuracy: 0.1983\n",
      "Epoch 851/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1089 - accuracy: 0.8899 - val_loss: 0.9352 - val_accuracy: 0.2057\n",
      "Epoch 852/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1094 - accuracy: 0.9003 - val_loss: 0.9338 - val_accuracy: 0.2089\n",
      "Epoch 853/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1085 - accuracy: 0.9021 - val_loss: 0.9344 - val_accuracy: 0.1962\n",
      "Epoch 854/1500\n",
      "126/126 [==============================] - 3s 23ms/step - loss: 0.1088 - accuracy: 0.8966 - val_loss: 0.9358 - val_accuracy: 0.1919\n",
      "Epoch 855/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1093 - accuracy: 0.8952 - val_loss: 0.9358 - val_accuracy: 0.1941\n",
      "Epoch 856/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1080 - accuracy: 0.9024 - val_loss: 0.9366 - val_accuracy: 0.1803\n",
      "Epoch 857/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1093 - accuracy: 0.9011 - val_loss: 0.9374 - val_accuracy: 0.1941\n",
      "Epoch 858/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1080 - accuracy: 0.9045 - val_loss: 0.9389 - val_accuracy: 0.1909\n",
      "Epoch 859/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1099 - accuracy: 0.8939 - val_loss: 0.9359 - val_accuracy: 0.1919\n",
      "Epoch 860/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1085 - accuracy: 0.9090 - val_loss: 0.9373 - val_accuracy: 0.1962\n",
      "Epoch 861/1500\n",
      "126/126 [==============================] - 5s 36ms/step - loss: 0.1106 - accuracy: 0.8928 - val_loss: 0.9371 - val_accuracy: 0.1909\n",
      "Epoch 862/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1085 - accuracy: 0.9016 - val_loss: 0.9383 - val_accuracy: 0.2142\n",
      "Epoch 863/1500\n",
      "126/126 [==============================] - 5s 36ms/step - loss: 0.1082 - accuracy: 0.9037 - val_loss: 0.9378 - val_accuracy: 0.1972\n",
      "Epoch 864/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1076 - accuracy: 0.9011 - val_loss: 0.9378 - val_accuracy: 0.1951\n",
      "Epoch 865/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1078 - accuracy: 0.9053 - val_loss: 0.9400 - val_accuracy: 0.1888\n",
      "Epoch 866/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1097 - accuracy: 0.8992 - val_loss: 0.9371 - val_accuracy: 0.2047\n",
      "Epoch 867/1500\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 0.1081 - accuracy: 0.8963 - val_loss: 0.9370 - val_accuracy: 0.1951\n",
      "Epoch 868/1500\n",
      "126/126 [==============================] - 4s 33ms/step - loss: 0.1070 - accuracy: 0.9080 - val_loss: 0.9368 - val_accuracy: 0.1919\n",
      "Epoch 869/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1090 - accuracy: 0.8878 - val_loss: 0.9377 - val_accuracy: 0.1951\n",
      "Epoch 870/1500\n",
      "126/126 [==============================] - 4s 32ms/step - loss: 0.1094 - accuracy: 0.8931 - val_loss: 0.9379 - val_accuracy: 0.1919\n",
      "Epoch 871/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1100 - accuracy: 0.8966 - val_loss: 0.9371 - val_accuracy: 0.2047\n",
      "Epoch 872/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1089 - accuracy: 0.8958 - val_loss: 0.9348 - val_accuracy: 0.2174\n",
      "Epoch 873/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1091 - accuracy: 0.8968 - val_loss: 0.9358 - val_accuracy: 0.2025\n",
      "Epoch 874/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1081 - accuracy: 0.9029 - val_loss: 0.9353 - val_accuracy: 0.1972\n",
      "Epoch 875/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1086 - accuracy: 0.8907 - val_loss: 0.9357 - val_accuracy: 0.1866\n",
      "Epoch 876/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1089 - accuracy: 0.8971 - val_loss: 0.9371 - val_accuracy: 0.1941\n",
      "Epoch 877/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1087 - accuracy: 0.8987 - val_loss: 0.9362 - val_accuracy: 0.1930\n",
      "Epoch 878/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1080 - accuracy: 0.8944 - val_loss: 0.9372 - val_accuracy: 0.1919\n",
      "Epoch 879/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1095 - accuracy: 0.8979 - val_loss: 0.9377 - val_accuracy: 0.2025\n",
      "Epoch 880/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1086 - accuracy: 0.9045 - val_loss: 0.9376 - val_accuracy: 0.1941\n",
      "Epoch 881/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1089 - accuracy: 0.8979 - val_loss: 0.9373 - val_accuracy: 0.1866\n",
      "Epoch 882/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1092 - accuracy: 0.8955 - val_loss: 0.9412 - val_accuracy: 0.1962\n",
      "Epoch 883/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1074 - accuracy: 0.8992 - val_loss: 0.9372 - val_accuracy: 0.1983\n",
      "Epoch 884/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1092 - accuracy: 0.9042 - val_loss: 0.9340 - val_accuracy: 0.1994\n",
      "Epoch 885/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1086 - accuracy: 0.9027 - val_loss: 0.9402 - val_accuracy: 0.1888\n",
      "Epoch 886/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1083 - accuracy: 0.8966 - val_loss: 0.9380 - val_accuracy: 0.1951\n",
      "Epoch 887/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1078 - accuracy: 0.8960 - val_loss: 0.9406 - val_accuracy: 0.1941\n",
      "Epoch 888/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1076 - accuracy: 0.8987 - val_loss: 0.9379 - val_accuracy: 0.1813\n",
      "Epoch 889/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1088 - accuracy: 0.9029 - val_loss: 0.9394 - val_accuracy: 0.1983\n",
      "Epoch 890/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1074 - accuracy: 0.8944 - val_loss: 0.9416 - val_accuracy: 0.1909\n",
      "Epoch 891/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1087 - accuracy: 0.8923 - val_loss: 0.9371 - val_accuracy: 0.1856\n",
      "Epoch 892/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1074 - accuracy: 0.9021 - val_loss: 0.9341 - val_accuracy: 0.1909\n",
      "Epoch 893/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1088 - accuracy: 0.8979 - val_loss: 0.9397 - val_accuracy: 0.1919\n",
      "Epoch 894/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1080 - accuracy: 0.8997 - val_loss: 0.9392 - val_accuracy: 0.1856\n",
      "Epoch 895/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1081 - accuracy: 0.8936 - val_loss: 0.9402 - val_accuracy: 0.1919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 896/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1080 - accuracy: 0.9119 - val_loss: 0.9390 - val_accuracy: 0.2015\n",
      "Epoch 897/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1070 - accuracy: 0.8997 - val_loss: 0.9387 - val_accuracy: 0.1919\n",
      "Epoch 898/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1088 - accuracy: 0.8931 - val_loss: 0.9381 - val_accuracy: 0.1930\n",
      "Epoch 899/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1078 - accuracy: 0.8960 - val_loss: 0.9374 - val_accuracy: 0.1835\n",
      "Epoch 900/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1081 - accuracy: 0.9011 - val_loss: 0.9367 - val_accuracy: 0.1930\n",
      "Epoch 901/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1087 - accuracy: 0.8947 - val_loss: 0.9363 - val_accuracy: 0.1909\n",
      "Epoch 902/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1082 - accuracy: 0.8928 - val_loss: 0.9384 - val_accuracy: 0.1930\n",
      "Epoch 903/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1076 - accuracy: 0.8944 - val_loss: 0.9367 - val_accuracy: 0.1941\n",
      "Epoch 904/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1085 - accuracy: 0.9045 - val_loss: 0.9403 - val_accuracy: 0.1930\n",
      "Epoch 905/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1094 - accuracy: 0.8989 - val_loss: 0.9419 - val_accuracy: 0.1962\n",
      "Epoch 906/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1092 - accuracy: 0.8947 - val_loss: 0.9389 - val_accuracy: 0.1835\n",
      "Epoch 907/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1087 - accuracy: 0.9056 - val_loss: 0.9388 - val_accuracy: 0.1983\n",
      "Epoch 908/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1070 - accuracy: 0.9019 - val_loss: 0.9401 - val_accuracy: 0.1856\n",
      "Epoch 909/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1084 - accuracy: 0.9053 - val_loss: 0.9377 - val_accuracy: 0.1919\n",
      "Epoch 910/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1078 - accuracy: 0.8984 - val_loss: 0.9351 - val_accuracy: 0.1962\n",
      "Epoch 911/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1079 - accuracy: 0.8905 - val_loss: 0.9388 - val_accuracy: 0.1930\n",
      "Epoch 912/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1091 - accuracy: 0.8976 - val_loss: 0.9381 - val_accuracy: 0.1930\n",
      "Epoch 913/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1082 - accuracy: 0.9005 - val_loss: 0.9383 - val_accuracy: 0.1962\n",
      "Epoch 914/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1070 - accuracy: 0.9077 - val_loss: 0.9355 - val_accuracy: 0.1930\n",
      "Epoch 915/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1080 - accuracy: 0.8947 - val_loss: 0.9394 - val_accuracy: 0.1919\n",
      "Epoch 916/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1070 - accuracy: 0.8955 - val_loss: 0.9388 - val_accuracy: 0.1983\n",
      "Epoch 917/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1078 - accuracy: 0.8963 - val_loss: 0.9396 - val_accuracy: 0.1983\n",
      "Epoch 918/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1069 - accuracy: 0.8902 - val_loss: 0.9376 - val_accuracy: 0.1972\n",
      "Epoch 919/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1073 - accuracy: 0.9072 - val_loss: 0.9392 - val_accuracy: 0.2015\n",
      "Epoch 920/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1066 - accuracy: 0.8968 - val_loss: 0.9399 - val_accuracy: 0.1930\n",
      "Epoch 921/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1059 - accuracy: 0.8950 - val_loss: 0.9354 - val_accuracy: 0.1919\n",
      "Epoch 922/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1056 - accuracy: 0.8971 - val_loss: 0.9351 - val_accuracy: 0.2036\n",
      "Epoch 923/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1074 - accuracy: 0.8973 - val_loss: 0.9363 - val_accuracy: 0.1888\n",
      "Epoch 924/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1067 - accuracy: 0.8960 - val_loss: 0.9364 - val_accuracy: 0.1930\n",
      "Epoch 925/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1066 - accuracy: 0.8979 - val_loss: 0.9354 - val_accuracy: 0.2015\n",
      "Epoch 926/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1076 - accuracy: 0.8984 - val_loss: 0.9387 - val_accuracy: 0.1941\n",
      "Epoch 927/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1057 - accuracy: 0.9090 - val_loss: 0.9391 - val_accuracy: 0.1983\n",
      "Epoch 928/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1074 - accuracy: 0.8960 - val_loss: 0.9376 - val_accuracy: 0.1983\n",
      "Epoch 929/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1069 - accuracy: 0.9024 - val_loss: 0.9404 - val_accuracy: 0.1983\n",
      "Epoch 930/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1060 - accuracy: 0.9042 - val_loss: 0.9389 - val_accuracy: 0.1930\n",
      "Epoch 931/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1079 - accuracy: 0.8984 - val_loss: 0.9402 - val_accuracy: 0.1951\n",
      "Epoch 932/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1063 - accuracy: 0.9024 - val_loss: 0.9389 - val_accuracy: 0.1983\n",
      "Epoch 933/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1070 - accuracy: 0.8971 - val_loss: 0.9368 - val_accuracy: 0.1951\n",
      "Epoch 934/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1071 - accuracy: 0.9034 - val_loss: 0.9400 - val_accuracy: 0.2057\n",
      "Epoch 935/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1070 - accuracy: 0.8973 - val_loss: 0.9406 - val_accuracy: 0.1930\n",
      "Epoch 936/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1068 - accuracy: 0.8947 - val_loss: 0.9381 - val_accuracy: 0.1898\n",
      "Epoch 937/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1079 - accuracy: 0.8995 - val_loss: 0.9389 - val_accuracy: 0.1951\n",
      "Epoch 938/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1074 - accuracy: 0.8976 - val_loss: 0.9373 - val_accuracy: 0.1994\n",
      "Epoch 939/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1062 - accuracy: 0.9011 - val_loss: 0.9399 - val_accuracy: 0.2004\n",
      "Epoch 940/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1073 - accuracy: 0.8958 - val_loss: 0.9394 - val_accuracy: 0.2100\n",
      "Epoch 941/1500\n",
      "126/126 [==============================] - 3s 28ms/step - loss: 0.1082 - accuracy: 0.8899 - val_loss: 0.9426 - val_accuracy: 0.1930\n",
      "Epoch 942/1500\n",
      "126/126 [==============================] - 4s 32ms/step - loss: 0.1075 - accuracy: 0.8997 - val_loss: 0.9435 - val_accuracy: 0.1941\n",
      "Epoch 943/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1075 - accuracy: 0.8952 - val_loss: 0.9402 - val_accuracy: 0.2025\n",
      "Epoch 944/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1078 - accuracy: 0.8971 - val_loss: 0.9387 - val_accuracy: 0.1919\n",
      "Epoch 945/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1068 - accuracy: 0.9042 - val_loss: 0.9397 - val_accuracy: 0.1909\n",
      "Epoch 946/1500\n",
      "126/126 [==============================] - 3s 24ms/step - loss: 0.1079 - accuracy: 0.8947 - val_loss: 0.9388 - val_accuracy: 0.1930\n",
      "Epoch 947/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1075 - accuracy: 0.9048 - val_loss: 0.9382 - val_accuracy: 0.1951\n",
      "Epoch 948/1500\n",
      "126/126 [==============================] - 3s 28ms/step - loss: 0.1070 - accuracy: 0.8947 - val_loss: 0.9391 - val_accuracy: 0.1930\n",
      "Epoch 949/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1074 - accuracy: 0.9024 - val_loss: 0.9366 - val_accuracy: 0.1983\n",
      "Epoch 950/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1075 - accuracy: 0.9024 - val_loss: 0.9395 - val_accuracy: 0.1919\n",
      "Epoch 951/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1069 - accuracy: 0.8958 - val_loss: 0.9375 - val_accuracy: 0.2036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 952/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1078 - accuracy: 0.8971 - val_loss: 0.9392 - val_accuracy: 0.1994\n",
      "Epoch 953/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1069 - accuracy: 0.8947 - val_loss: 0.9403 - val_accuracy: 0.1898\n",
      "Epoch 954/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1076 - accuracy: 0.9019 - val_loss: 0.9384 - val_accuracy: 0.1941\n",
      "Epoch 955/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1084 - accuracy: 0.8968 - val_loss: 0.9401 - val_accuracy: 0.2025\n",
      "Epoch 956/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1062 - accuracy: 0.9037 - val_loss: 0.9366 - val_accuracy: 0.1919\n",
      "Epoch 957/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1067 - accuracy: 0.9034 - val_loss: 0.9364 - val_accuracy: 0.2015\n",
      "Epoch 958/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1061 - accuracy: 0.9056 - val_loss: 0.9351 - val_accuracy: 0.1930\n",
      "Epoch 959/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1076 - accuracy: 0.8963 - val_loss: 0.9373 - val_accuracy: 0.2015\n",
      "Epoch 960/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1067 - accuracy: 0.9013 - val_loss: 0.9377 - val_accuracy: 0.1930\n",
      "Epoch 961/1500\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 0.1065 - accuracy: 0.8955 - val_loss: 0.9377 - val_accuracy: 0.1983\n",
      "Epoch 962/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1061 - accuracy: 0.8987 - val_loss: 0.9411 - val_accuracy: 0.1941\n",
      "Epoch 963/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1064 - accuracy: 0.9021 - val_loss: 0.9400 - val_accuracy: 0.1941\n",
      "Epoch 964/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1075 - accuracy: 0.8981 - val_loss: 0.9371 - val_accuracy: 0.1962\n",
      "Epoch 965/1500\n",
      "126/126 [==============================] - 3s 28ms/step - loss: 0.1067 - accuracy: 0.8955 - val_loss: 0.9382 - val_accuracy: 0.1898\n",
      "Epoch 966/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1060 - accuracy: 0.9037 - val_loss: 0.9398 - val_accuracy: 0.1877\n",
      "Epoch 967/1500\n",
      "126/126 [==============================] - 4s 35ms/step - loss: 0.1058 - accuracy: 0.8981 - val_loss: 0.9381 - val_accuracy: 0.1972\n",
      "Epoch 968/1500\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 0.1055 - accuracy: 0.8987 - val_loss: 0.9408 - val_accuracy: 0.1877\n",
      "Epoch 969/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1062 - accuracy: 0.9082 - val_loss: 0.9371 - val_accuracy: 0.1930\n",
      "Epoch 970/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1064 - accuracy: 0.9034 - val_loss: 0.9380 - val_accuracy: 0.1983\n",
      "Epoch 971/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1058 - accuracy: 0.9008 - val_loss: 0.9363 - val_accuracy: 0.1845\n",
      "Epoch 972/1500\n",
      "126/126 [==============================] - 3s 25ms/step - loss: 0.1058 - accuracy: 0.9003 - val_loss: 0.9374 - val_accuracy: 0.1951\n",
      "Epoch 973/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1058 - accuracy: 0.8995 - val_loss: 0.9369 - val_accuracy: 0.1813\n",
      "Epoch 974/1500\n",
      "126/126 [==============================] - 4s 33ms/step - loss: 0.1062 - accuracy: 0.8867 - val_loss: 0.9390 - val_accuracy: 0.1909\n",
      "Epoch 975/1500\n",
      "126/126 [==============================] - 3s 28ms/step - loss: 0.1047 - accuracy: 0.9053 - val_loss: 0.9389 - val_accuracy: 0.1919\n",
      "Epoch 976/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1062 - accuracy: 0.9053 - val_loss: 0.9370 - val_accuracy: 0.2025\n",
      "Epoch 977/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1055 - accuracy: 0.9064 - val_loss: 0.9385 - val_accuracy: 0.1983\n",
      "Epoch 978/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1050 - accuracy: 0.8989 - val_loss: 0.9408 - val_accuracy: 0.1972\n",
      "Epoch 979/1500\n",
      "126/126 [==============================] - 4s 35ms/step - loss: 0.1049 - accuracy: 0.9029 - val_loss: 0.9354 - val_accuracy: 0.1866\n",
      "Epoch 980/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1061 - accuracy: 0.9003 - val_loss: 0.9387 - val_accuracy: 0.1951\n",
      "Epoch 981/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1052 - accuracy: 0.8979 - val_loss: 0.9379 - val_accuracy: 0.1972\n",
      "Epoch 982/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1054 - accuracy: 0.9024 - val_loss: 0.9378 - val_accuracy: 0.2004\n",
      "Epoch 983/1500\n",
      "126/126 [==============================] - 4s 31ms/step - loss: 0.1059 - accuracy: 0.8992 - val_loss: 0.9352 - val_accuracy: 0.1962\n",
      "Epoch 984/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1070 - accuracy: 0.9034 - val_loss: 0.9371 - val_accuracy: 0.2015\n",
      "Epoch 985/1500\n",
      "126/126 [==============================] - 4s 36ms/step - loss: 0.1076 - accuracy: 0.8997 - val_loss: 0.9357 - val_accuracy: 0.2004\n",
      "Epoch 986/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1067 - accuracy: 0.9011 - val_loss: 0.9363 - val_accuracy: 0.1930\n",
      "Epoch 987/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1062 - accuracy: 0.8997 - val_loss: 0.9355 - val_accuracy: 0.1962\n",
      "Epoch 988/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1064 - accuracy: 0.9021 - val_loss: 0.9360 - val_accuracy: 0.2015\n",
      "Epoch 989/1500\n",
      "126/126 [==============================] - 4s 28ms/step - loss: 0.1062 - accuracy: 0.9027 - val_loss: 0.9374 - val_accuracy: 0.1856\n",
      "Epoch 990/1500\n",
      "126/126 [==============================] - 4s 30ms/step - loss: 0.1063 - accuracy: 0.9064 - val_loss: 0.9351 - val_accuracy: 0.1962\n",
      "Epoch 991/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1064 - accuracy: 0.8968 - val_loss: 0.9368 - val_accuracy: 0.1962\n",
      "Epoch 992/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1051 - accuracy: 0.9021 - val_loss: 0.9333 - val_accuracy: 0.1994\n",
      "Epoch 993/1500\n",
      "126/126 [==============================] - 4s 29ms/step - loss: 0.1059 - accuracy: 0.9008 - val_loss: 0.9361 - val_accuracy: 0.2078\n",
      "Epoch 994/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1054 - accuracy: 0.9032 - val_loss: 0.9364 - val_accuracy: 0.2047\n",
      "Epoch 995/1500\n",
      "126/126 [==============================] - 3s 26ms/step - loss: 0.1058 - accuracy: 0.8952 - val_loss: 0.9357 - val_accuracy: 0.1972\n",
      "Epoch 996/1500\n",
      "126/126 [==============================] - 3s 27ms/step - loss: 0.1058 - accuracy: 0.9048 - val_loss: 0.9365 - val_accuracy: 0.2025\n",
      "Epoch 996: early stopping\n"
     ]
    }
   ],
   "source": [
    "training_history_dense = dense.fit(X_train, y_train, validation_split = 0.2, epochs = epochs, batch_size = batch_size, verbose = 1, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f8099a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "996 996\n"
     ]
    }
   ],
   "source": [
    "acc_dense = training_history_dense.history['accuracy']\n",
    "val_acc_dense = training_history_dense.history['val_accuracy']\n",
    "\n",
    "print(len(acc_dense), len(val_acc_dense))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1e7ab7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Labels des axes\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Courbe du score de validation du réseau Dense\n",
    "plt.plot(np.arange(1 , len(acc_dense)+1, 1),\n",
    "         val_acc_dense,\n",
    "         label = 'val',\n",
    "         color = 'blue')\n",
    "\n",
    "# Courbe du score d'entrainement du réseau Dense\n",
    "plt.plot(np.arange(1 , len(acc_dense)+1, 1),\n",
    "         acc_dense,\n",
    "         label = 'train',\n",
    "         color = 'red')\n",
    "\n",
    "# Affichage de la légende\n",
    "plt.legend()\n",
    "\n",
    "# Affichage de la figure\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
